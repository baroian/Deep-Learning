{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: keras in /vol/home/s4422090/.local/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: numpy in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: requests in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: matplotlib in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: setuptools in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rich in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /vol/home/s4422090/.local/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /vol/home/s4422090/.local/lib/python3.12/site-packages (from keras) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /vol/home/s4422090/.local/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras numpy requests scikit-learn matplotlib ConfigSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  4 12:09:29 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| 32%   29C    P8              N/A / 115W |     69MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    307552      G   /usr/lib/xorg/Xorg                           56MiB |\n",
      "|    0   N/A  N/A    307585      G   /usr/bin/gnome-shell                          5MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth set for GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth set for GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FASHION MNIST baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Num GPUs Available: 1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "X_train shape: (54000, 28, 28)\n",
      "54000 train samples\n",
      "10000 test samples\n",
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.7156 - loss: 0.8518 - val_accuracy: 0.8748 - val_loss: 0.3412\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.3882 - val_accuracy: 0.8927 - val_loss: 0.2800\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.3206 - val_accuracy: 0.9040 - val_loss: 0.2572\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2767 - val_accuracy: 0.9087 - val_loss: 0.2446\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2533 - val_accuracy: 0.9095 - val_loss: 0.2412\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2258 - val_accuracy: 0.9180 - val_loss: 0.2349\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.2081 - val_accuracy: 0.9163 - val_loss: 0.2227\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.1874 - val_accuracy: 0.9207 - val_loss: 0.2190\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 0.1735 - val_accuracy: 0.9203 - val_loss: 0.2221\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1601 - val_accuracy: 0.9227 - val_loss: 0.2282\n",
      "Test loss: 0.2447768598794937\n",
      "Test accuracy: 0.917900025844574\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Verify TensorFlow installation and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for each GPU to prevent TensorFlow from allocating all GPU memory at once\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")\n",
    "\n",
    "\n",
    "# 1. Load the Fashion MNIST dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 2. Normalize the input data to [0, 1] range\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# 3. Split the full training set into training and validation sets\n",
    "val_ration = 0.1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=val_ration, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 4. Define class names for reference (optional)\n",
    "class_names = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "\n",
    "# 5. Print dataset shapes for verification\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# 6. Reshape input data based on the Keras backend\n",
    "img_rows, img_cols = 28, 28  # Fashion MNIST images are 28x28 pixels\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# 7. Convert class vectors to binary class matrices (one-hot encoding)\n",
    "num_classes = 10  # There are 10 classes in Fashion MNIST\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_valid = to_categorical(y_valid, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "kernel_initializer='he_normal'\n",
    "\n",
    "# 8. Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(28, kernel_size=(3, 3), activation='relu', input_shape=input_shape, kernel_initializer = kernel_initializer),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_initializer = kernel_initializer),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_initializer = kernel_initializer),\n",
    "    Dropout(0.5),   \n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "# 9. Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',      # Suitable loss function for multi-class classification\n",
    "    optimizer='adam',                     # Adam optimizer\n",
    "    metrics=['accuracy']                  # Evaluate performance using accuracy\n",
    ")\n",
    "\n",
    "# 10. Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(X_valid, y_valid)    # Use validation set for monitoring\n",
    ")\n",
    "\n",
    "# 11. Evaluate the model on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ConfigSpace\n",
      "  Downloading configspace-1.2.0.tar.gz (130 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from ConfigSpace) (2.0.2)\n",
      "Requirement already satisfied: pyparsing in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from ConfigSpace) (3.2.0)\n",
      "Requirement already satisfied: scipy in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from ConfigSpace) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from ConfigSpace) (4.11.0)\n",
      "Collecting more-itertools (from ConfigSpace)\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Building wheels for collected packages: ConfigSpace\n",
      "  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ConfigSpace: filename=ConfigSpace-1.2.0-py3-none-any.whl size=115855 sha256=0b4c4e2777de156083e56e93f4409c672c9bd4b8300b23e84fdd1450885b311c\n",
      "  Stored in directory: /vol/home/s4422090/.cache/pip/wheels/1c/c1/6b/8c7b7a188c6753c0b2e2fca5cfe7dd7d1e2fbb52eed0e54c75\n",
      "Successfully built ConfigSpace\n",
      "Installing collected packages: more-itertools, ConfigSpace\n",
      "Successfully installed ConfigSpace-1.2.0 more-itertools-10.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ConfigSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2233872/3531416474.py:106: DeprecationWarning: Please use `space.add(hyperparameters)`\n",
      "  cs.add_hyperparameters([filters, kernel_size, activation, optimizer, batch_size, epochs, kernel_initializer, dropout_rate, max_pool_size, FC_size])\n",
      "/tmp/ipykernel_2233872/3531416474.py:116: DeprecationWarning: Please use `dict(config)` instead of `config.get_dictionary()` or use it as a dictionary directly if needed.\n",
      "  config_dict = config.get_dictionary()\n",
      "/vol/home/s4422090/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations to evaluate: 384\n",
      "Evaluating configuration 1/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9220\n",
      "\n",
      "Evaluating configuration 2/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:08:29.720203: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:08:29.894474: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 13:08:29.976657: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 300 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2024-11-04 13:08:34.017436: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:08:34.222880: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:08:34.415074: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:08:34.457055: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 13:08:34.868411: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 744 bytes spill stores, 712 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8487\n",
      "\n",
      "Evaluating configuration 3/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9183\n",
      "\n",
      "Evaluating configuration 4/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:09:23.296940: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:09:26.825328: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:09:26.956209: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:09:27.033548: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:09:27.119988: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8273\n",
      "\n",
      "Evaluating configuration 5/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9175\n",
      "\n",
      "Evaluating configuration 6/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:10:19.453476: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2024-11-04 13:10:19.543444: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 13:10:19.602855: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 13:10:23.380663: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:10:23.424629: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:10:23.676825: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 13:10:23.906307: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8450\n",
      "\n",
      "Evaluating configuration 7/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9082\n",
      "\n",
      "Evaluating configuration 8/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:11:18.892830: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 13:11:18.959466: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 13:11:23.093577: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:11:23.193613: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:11:23.350972: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8425\n",
      "\n",
      "Evaluating configuration 9/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9270\n",
      "\n",
      "Evaluating configuration 10/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8812\n",
      "\n",
      "Evaluating configuration 11/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9272\n",
      "\n",
      "Evaluating configuration 12/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8790\n",
      "\n",
      "Evaluating configuration 13/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9197\n",
      "\n",
      "Evaluating configuration 14/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8758\n",
      "\n",
      "Evaluating configuration 15/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9095\n",
      "\n",
      "Evaluating configuration 16/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8640\n",
      "\n",
      "Evaluating configuration 17/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9237\n",
      "\n",
      "Evaluating configuration 18/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:16:13.421022: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:16:13.521992: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 300 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2024-11-04 13:16:18.949306: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:16:19.009758: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:16:19.161429: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:16:19.272111: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-04 13:16:19.603707: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 744 bytes spill stores, 712 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8507\n",
      "\n",
      "Evaluating configuration 19/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9268\n",
      "\n",
      "Evaluating configuration 20/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:17:40.932152: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2024-11-04 13:17:41.080787: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:17:46.288558: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:17:46.363138: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:17:46.454987: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-04 13:17:46.473254: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:17:46.562477: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8543\n",
      "\n",
      "Evaluating configuration 21/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9167\n",
      "\n",
      "Evaluating configuration 22/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:19:12.503742: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 13:19:12.524666: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 13:19:12.790892: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 288 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2024-11-04 13:19:18.214566: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:19:18.319719: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:19:18.567454: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 13:19:18.881335: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 732 bytes spill stores, 700 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8603\n",
      "\n",
      "Evaluating configuration 23/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9105\n",
      "\n",
      "Evaluating configuration 24/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 13:20:46.752549: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2024-11-04 13:20:46.797839: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 13:20:46.802185: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 13:20:51.766585: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 13:20:51.863686: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 13:20:52.131294: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 13:20:52.292995: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8547\n",
      "\n",
      "Evaluating configuration 25/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9285\n",
      "\n",
      "Evaluating configuration 26/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8850\n",
      "\n",
      "Evaluating configuration 27/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9278\n",
      "\n",
      "Evaluating configuration 28/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8863\n",
      "\n",
      "Evaluating configuration 29/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9180\n",
      "\n",
      "Evaluating configuration 30/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8808\n",
      "\n",
      "Evaluating configuration 31/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9157\n",
      "\n",
      "Evaluating configuration 32/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8642\n",
      "\n",
      "Evaluating configuration 33/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9242\n",
      "\n",
      "Evaluating configuration 34/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8308\n",
      "\n",
      "Evaluating configuration 35/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9235\n",
      "\n",
      "Evaluating configuration 36/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8298\n",
      "\n",
      "Evaluating configuration 37/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9180\n",
      "\n",
      "Evaluating configuration 38/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8360\n",
      "\n",
      "Evaluating configuration 39/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9087\n",
      "\n",
      "Evaluating configuration 40/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8380\n",
      "\n",
      "Evaluating configuration 41/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9247\n",
      "\n",
      "Evaluating configuration 42/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8768\n",
      "\n",
      "Evaluating configuration 43/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9307\n",
      "\n",
      "Evaluating configuration 44/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8745\n",
      "\n",
      "Evaluating configuration 45/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9170\n",
      "\n",
      "Evaluating configuration 46/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8695\n",
      "\n",
      "Evaluating configuration 47/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9153\n",
      "\n",
      "Evaluating configuration 48/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8557\n",
      "\n",
      "Evaluating configuration 49/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9247\n",
      "\n",
      "Evaluating configuration 50/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8392\n",
      "\n",
      "Evaluating configuration 51/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9275\n",
      "\n",
      "Evaluating configuration 52/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8367\n",
      "\n",
      "Evaluating configuration 53/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9188\n",
      "\n",
      "Evaluating configuration 54/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8512\n",
      "\n",
      "Evaluating configuration 55/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9180\n",
      "\n",
      "Evaluating configuration 56/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8427\n",
      "\n",
      "Evaluating configuration 57/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9270\n",
      "\n",
      "Evaluating configuration 58/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8895\n",
      "\n",
      "Evaluating configuration 59/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9232\n",
      "\n",
      "Evaluating configuration 60/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8820\n",
      "\n",
      "Evaluating configuration 61/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9208\n",
      "\n",
      "Evaluating configuration 62/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8807\n",
      "\n",
      "Evaluating configuration 63/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9153\n",
      "\n",
      "Evaluating configuration 64/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8708\n",
      "\n",
      "Evaluating configuration 65/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9245\n",
      "\n",
      "Evaluating configuration 66/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8140\n",
      "\n",
      "Evaluating configuration 67/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9220\n",
      "\n",
      "Evaluating configuration 68/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8055\n",
      "\n",
      "Evaluating configuration 69/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9177\n",
      "\n",
      "Evaluating configuration 70/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Evaluating configuration 71/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9017\n",
      "\n",
      "Evaluating configuration 72/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8133\n",
      "\n",
      "Evaluating configuration 73/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9245\n",
      "\n",
      "Evaluating configuration 74/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8797\n",
      "\n",
      "Evaluating configuration 75/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9233\n",
      "\n",
      "Evaluating configuration 76/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8670\n",
      "\n",
      "Evaluating configuration 77/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9187\n",
      "\n",
      "Evaluating configuration 78/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8687\n",
      "\n",
      "Evaluating configuration 79/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9062\n",
      "\n",
      "Evaluating configuration 80/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8425\n",
      "\n",
      "Evaluating configuration 81/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9238\n",
      "\n",
      "Evaluating configuration 82/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8245\n",
      "\n",
      "Evaluating configuration 83/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9252\n",
      "\n",
      "Evaluating configuration 84/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8238\n",
      "\n",
      "Evaluating configuration 85/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9188\n",
      "\n",
      "Evaluating configuration 86/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8407\n",
      "\n",
      "Evaluating configuration 87/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9157\n",
      "\n",
      "Evaluating configuration 88/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8282\n",
      "\n",
      "Evaluating configuration 89/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9307\n",
      "\n",
      "Evaluating configuration 90/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8908\n",
      "\n",
      "Evaluating configuration 91/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9217\n",
      "\n",
      "Evaluating configuration 92/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8737\n",
      "\n",
      "Evaluating configuration 93/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9183\n",
      "\n",
      "Evaluating configuration 94/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8772\n",
      "\n",
      "Evaluating configuration 95/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9152\n",
      "\n",
      "Evaluating configuration 96/384: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8665\n",
      "\n",
      "Evaluating configuration 97/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8177\n",
      "\n",
      "Evaluating configuration 98/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 99/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8820\n",
      "\n",
      "Evaluating configuration 100/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0978\n",
      "\n",
      "Evaluating configuration 101/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8785\n",
      "\n",
      "Evaluating configuration 102/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6818\n",
      "\n",
      "Evaluating configuration 103/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8793\n",
      "\n",
      "Evaluating configuration 104/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.1690\n",
      "\n",
      "Evaluating configuration 105/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8973\n",
      "\n",
      "Evaluating configuration 106/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7473\n",
      "\n",
      "Evaluating configuration 107/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8938\n",
      "\n",
      "Evaluating configuration 108/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7180\n",
      "\n",
      "Evaluating configuration 109/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8802\n",
      "\n",
      "Evaluating configuration 110/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7243\n",
      "\n",
      "Evaluating configuration 111/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8920\n",
      "\n",
      "Evaluating configuration 112/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6887\n",
      "\n",
      "Evaluating configuration 113/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0978\n",
      "\n",
      "Evaluating configuration 114/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.4377\n",
      "\n",
      "Evaluating configuration 115/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 116/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 117/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1013\n",
      "\n",
      "Evaluating configuration 118/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7158\n",
      "\n",
      "Evaluating configuration 119/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8722\n",
      "\n",
      "Evaluating configuration 120/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6397\n",
      "\n",
      "Evaluating configuration 121/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 122/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7593\n",
      "\n",
      "Evaluating configuration 123/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8932\n",
      "\n",
      "Evaluating configuration 124/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7405\n",
      "\n",
      "Evaluating configuration 125/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 126/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7358\n",
      "\n",
      "Evaluating configuration 127/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8908\n",
      "\n",
      "Evaluating configuration 128/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7125\n",
      "\n",
      "Evaluating configuration 129/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1032\n",
      "\n",
      "Evaluating configuration 130/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 131/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8727\n",
      "\n",
      "Evaluating configuration 132/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.1013\n",
      "\n",
      "Evaluating configuration 133/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8767\n",
      "\n",
      "Evaluating configuration 134/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 135/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8667\n",
      "\n",
      "Evaluating configuration 136/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0978\n",
      "\n",
      "Evaluating configuration 137/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8975\n",
      "\n",
      "Evaluating configuration 138/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7472\n",
      "\n",
      "Evaluating configuration 139/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8987\n",
      "\n",
      "Evaluating configuration 140/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6923\n",
      "\n",
      "Evaluating configuration 141/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8792\n",
      "\n",
      "Evaluating configuration 142/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7205\n",
      "\n",
      "Evaluating configuration 143/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8863\n",
      "\n",
      "Evaluating configuration 144/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6838\n",
      "\n",
      "Evaluating configuration 145/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 146/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.1045\n",
      "\n",
      "Evaluating configuration 147/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8222\n",
      "\n",
      "Evaluating configuration 148/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 149/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 150/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.4872\n",
      "\n",
      "Evaluating configuration 151/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8652\n",
      "\n",
      "Evaluating configuration 152/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.4032\n",
      "\n",
      "Evaluating configuration 153/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0995\n",
      "\n",
      "Evaluating configuration 154/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7492\n",
      "\n",
      "Evaluating configuration 155/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8930\n",
      "\n",
      "Evaluating configuration 156/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7358\n",
      "\n",
      "Evaluating configuration 157/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8902\n",
      "\n",
      "Evaluating configuration 158/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7322\n",
      "\n",
      "Evaluating configuration 159/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8715\n",
      "\n",
      "Evaluating configuration 160/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7065\n",
      "\n",
      "Evaluating configuration 161/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1018\n",
      "\n",
      "Evaluating configuration 162/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 163/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8667\n",
      "\n",
      "Evaluating configuration 164/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 165/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8713\n",
      "\n",
      "Evaluating configuration 166/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 167/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8628\n",
      "\n",
      "Evaluating configuration 168/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 169/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8913\n",
      "\n",
      "Evaluating configuration 170/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7328\n",
      "\n",
      "Evaluating configuration 171/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8890\n",
      "\n",
      "Evaluating configuration 172/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7060\n",
      "\n",
      "Evaluating configuration 173/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8818\n",
      "\n",
      "Evaluating configuration 174/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7097\n",
      "\n",
      "Evaluating configuration 175/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8745\n",
      "\n",
      "Evaluating configuration 176/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6302\n",
      "\n",
      "Evaluating configuration 177/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 178/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 179/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8605\n",
      "\n",
      "Evaluating configuration 180/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0978\n",
      "\n",
      "Evaluating configuration 181/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 182/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 183/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8603\n",
      "\n",
      "Evaluating configuration 184/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.1013\n",
      "\n",
      "Evaluating configuration 185/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1045\n",
      "\n",
      "Evaluating configuration 186/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7475\n",
      "\n",
      "Evaluating configuration 187/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8893\n",
      "\n",
      "Evaluating configuration 188/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7310\n",
      "\n",
      "Evaluating configuration 189/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8843\n",
      "\n",
      "Evaluating configuration 190/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7310\n",
      "\n",
      "Evaluating configuration 191/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8825\n",
      "\n",
      "Evaluating configuration 192/384: {'FC_size': 128, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6850\n",
      "\n",
      "Evaluating configuration 193/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9268\n",
      "\n",
      "Evaluating configuration 194/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:34:59.668365: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 300 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2024-11-04 14:34:59.678354: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:34:59.696711: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:01.492633: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:01.508797: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:01.600639: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:01.620540: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:01.622613: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:01.711560: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 744 bytes spill stores, 712 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8550\n",
      "\n",
      "Evaluating configuration 195/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9250\n",
      "\n",
      "Evaluating configuration 196/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:35:23.852509: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:23.879275: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:25.539667: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:25.549274: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:25.601642: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:25.608844: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:25.697128: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:25.748474: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8507\n",
      "\n",
      "Evaluating configuration 197/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9182\n",
      "\n",
      "Evaluating configuration 198/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:35:49.399794: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:49.473187: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:49.477042: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:49.519082: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 288 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:51.384851: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:51.446231: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:51.543181: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:51.575927: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 14:35:51.576581: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 732 bytes spill stores, 700 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8568\n",
      "\n",
      "Evaluating configuration 199/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9148\n",
      "\n",
      "Evaluating configuration 200/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:36:16.111115: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:16.139281: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:16.158718: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:16.216412: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:18.000421: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:18.058623: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:18.088788: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:18.090092: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:36:18.148551: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709_0', 192 bytes spill stores, 192 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8465\n",
      "\n",
      "Evaluating configuration 201/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9260\n",
      "\n",
      "Evaluating configuration 202/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8912\n",
      "\n",
      "Evaluating configuration 203/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9265\n",
      "\n",
      "Evaluating configuration 204/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8875\n",
      "\n",
      "Evaluating configuration 205/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9155\n",
      "\n",
      "Evaluating configuration 206/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8797\n",
      "\n",
      "Evaluating configuration 207/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9138\n",
      "\n",
      "Evaluating configuration 208/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8695\n",
      "\n",
      "Evaluating configuration 209/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9315\n",
      "\n",
      "Evaluating configuration 210/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:38:36.582627: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:38:36.688436: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 300 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2024-11-04 14:38:40.047589: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:38:40.085117: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:38:40.107628: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:38:40.158408: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-04 14:38:40.172405: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-04 14:38:40.293845: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 744 bytes spill stores, 712 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8567\n",
      "\n",
      "Evaluating configuration 211/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9260\n",
      "\n",
      "Evaluating configuration 212/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:39:33.673835: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:39:33.774669: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 300 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2024-11-04 14:39:36.950831: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:39:36.954580: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:39:37.016147: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-04 14:39:37.050700: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2024-11-04 14:39:37.079654: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:39:37.216813: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 744 bytes spill stores, 712 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8597\n",
      "\n",
      "Evaluating configuration 213/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9217\n",
      "\n",
      "Evaluating configuration 214/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:40:30.567426: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:30.598219: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:30.629231: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 288 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:30.647047: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:33.869342: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:33.927770: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:34.030481: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:34.032265: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-04 14:40:34.153570: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 732 bytes spill stores, 700 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8662\n",
      "\n",
      "Evaluating configuration 215/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9195\n",
      "\n",
      "Evaluating configuration 216/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 14:41:25.314891: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:25.350287: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:25.372011: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:25.386177: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 288 bytes spill stores, 268 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:28.536320: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:28.556196: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:28.662305: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 72 bytes spill stores, 72 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:28.677851: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-11-04 14:41:28.787953: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_709', 732 bytes spill stores, 700 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8512\n",
      "\n",
      "Evaluating configuration 217/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9268\n",
      "\n",
      "Evaluating configuration 218/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8957\n",
      "\n",
      "Evaluating configuration 219/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9282\n",
      "\n",
      "Evaluating configuration 220/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8935\n",
      "\n",
      "Evaluating configuration 221/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9217\n",
      "\n",
      "Evaluating configuration 222/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8877\n",
      "\n",
      "Evaluating configuration 223/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9142\n",
      "\n",
      "Evaluating configuration 224/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8792\n",
      "\n",
      "Evaluating configuration 225/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9288\n",
      "\n",
      "Evaluating configuration 226/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8483\n",
      "\n",
      "Evaluating configuration 227/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9243\n",
      "\n",
      "Evaluating configuration 228/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8422\n",
      "\n",
      "Evaluating configuration 229/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9210\n",
      "\n",
      "Evaluating configuration 230/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8490\n",
      "\n",
      "Evaluating configuration 231/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9080\n",
      "\n",
      "Evaluating configuration 232/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8350\n",
      "\n",
      "Evaluating configuration 233/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9303\n",
      "\n",
      "Evaluating configuration 234/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8837\n",
      "\n",
      "Evaluating configuration 235/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9275\n",
      "\n",
      "Evaluating configuration 236/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8735\n",
      "\n",
      "Evaluating configuration 237/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9243\n",
      "\n",
      "Evaluating configuration 238/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8767\n",
      "\n",
      "Evaluating configuration 239/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9087\n",
      "\n",
      "Evaluating configuration 240/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8608\n",
      "\n",
      "Evaluating configuration 241/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9288\n",
      "\n",
      "Evaluating configuration 242/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8542\n",
      "\n",
      "Evaluating configuration 243/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9303\n",
      "\n",
      "Evaluating configuration 244/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8527\n",
      "\n",
      "Evaluating configuration 245/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9217\n",
      "\n",
      "Evaluating configuration 246/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8562\n",
      "\n",
      "Evaluating configuration 247/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9153\n",
      "\n",
      "Evaluating configuration 248/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8435\n",
      "\n",
      "Evaluating configuration 249/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9262\n",
      "\n",
      "Evaluating configuration 250/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8912\n",
      "\n",
      "Evaluating configuration 251/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9352\n",
      "\n",
      "Evaluating configuration 252/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8867\n",
      "\n",
      "Evaluating configuration 253/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9177\n",
      "\n",
      "Evaluating configuration 254/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8848\n",
      "\n",
      "Evaluating configuration 255/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9138\n",
      "\n",
      "Evaluating configuration 256/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8732\n",
      "\n",
      "Evaluating configuration 257/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9260\n",
      "\n",
      "Evaluating configuration 258/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8155\n",
      "\n",
      "Evaluating configuration 259/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9228\n",
      "\n",
      "Evaluating configuration 260/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8335\n",
      "\n",
      "Evaluating configuration 261/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9230\n",
      "\n",
      "Evaluating configuration 262/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8362\n",
      "\n",
      "Evaluating configuration 263/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9128\n",
      "\n",
      "Evaluating configuration 264/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8213\n",
      "\n",
      "Evaluating configuration 265/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9260\n",
      "\n",
      "Evaluating configuration 266/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8758\n",
      "\n",
      "Evaluating configuration 267/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9292\n",
      "\n",
      "Evaluating configuration 268/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8698\n",
      "\n",
      "Evaluating configuration 269/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9242\n",
      "\n",
      "Evaluating configuration 270/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8690\n",
      "\n",
      "Evaluating configuration 271/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9145\n",
      "\n",
      "Evaluating configuration 272/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8523\n",
      "\n",
      "Evaluating configuration 273/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9325\n",
      "\n",
      "Evaluating configuration 274/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8393\n",
      "\n",
      "Evaluating configuration 275/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9307\n",
      "\n",
      "Evaluating configuration 276/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8292\n",
      "\n",
      "Evaluating configuration 277/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9220\n",
      "\n",
      "Evaluating configuration 278/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8410\n",
      "\n",
      "Evaluating configuration 279/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9148\n",
      "\n",
      "Evaluating configuration 280/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8355\n",
      "\n",
      "Evaluating configuration 281/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9285\n",
      "\n",
      "Evaluating configuration 282/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8862\n",
      "\n",
      "Evaluating configuration 283/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9220\n",
      "\n",
      "Evaluating configuration 284/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8807\n",
      "\n",
      "Evaluating configuration 285/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9225\n",
      "\n",
      "Evaluating configuration 286/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8803\n",
      "\n",
      "Evaluating configuration 287/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9158\n",
      "\n",
      "Evaluating configuration 288/384: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.8663\n",
      "\n",
      "Evaluating configuration 289/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0995\n",
      "\n",
      "Evaluating configuration 290/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0925\n",
      "\n",
      "Evaluating configuration 291/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8865\n",
      "\n",
      "Evaluating configuration 292/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 293/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8817\n",
      "\n",
      "Evaluating configuration 294/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7082\n",
      "\n",
      "Evaluating configuration 295/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8778\n",
      "\n",
      "Evaluating configuration 296/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.3048\n",
      "\n",
      "Evaluating configuration 297/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9002\n",
      "\n",
      "Evaluating configuration 298/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7495\n",
      "\n",
      "Evaluating configuration 299/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8977\n",
      "\n",
      "Evaluating configuration 300/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7297\n",
      "\n",
      "Evaluating configuration 301/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8897\n",
      "\n",
      "Evaluating configuration 302/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7257\n",
      "\n",
      "Evaluating configuration 303/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8895\n",
      "\n",
      "Evaluating configuration 304/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6960\n",
      "\n",
      "Evaluating configuration 305/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0978\n",
      "\n",
      "Evaluating configuration 306/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.4660\n",
      "\n",
      "Evaluating configuration 307/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8757\n",
      "\n",
      "Evaluating configuration 308/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0978\n",
      "\n",
      "Evaluating configuration 309/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1018\n",
      "\n",
      "Evaluating configuration 310/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7235\n",
      "\n",
      "Evaluating configuration 311/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8770\n",
      "\n",
      "Evaluating configuration 312/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6825\n",
      "\n",
      "Evaluating configuration 313/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 314/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7643\n",
      "\n",
      "Evaluating configuration 315/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8950\n",
      "\n",
      "Evaluating configuration 316/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7455\n",
      "\n",
      "Evaluating configuration 317/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8957\n",
      "\n",
      "Evaluating configuration 318/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7405\n",
      "\n",
      "Evaluating configuration 319/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8902\n",
      "\n",
      "Evaluating configuration 320/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7158\n",
      "\n",
      "Evaluating configuration 321/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8428\n",
      "\n",
      "Evaluating configuration 322/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.1035\n",
      "\n",
      "Evaluating configuration 323/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8785\n",
      "\n",
      "Evaluating configuration 324/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 325/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8843\n",
      "\n",
      "Evaluating configuration 326/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6588\n",
      "\n",
      "Evaluating configuration 327/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8842\n",
      "\n",
      "Evaluating configuration 328/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.4635\n",
      "\n",
      "Evaluating configuration 329/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8883\n",
      "\n",
      "Evaluating configuration 330/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7443\n",
      "\n",
      "Evaluating configuration 331/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9003\n",
      "\n",
      "Evaluating configuration 332/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7208\n",
      "\n",
      "Evaluating configuration 333/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8932\n",
      "\n",
      "Evaluating configuration 334/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7238\n",
      "\n",
      "Evaluating configuration 335/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8935\n",
      "\n",
      "Evaluating configuration 336/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6918\n",
      "\n",
      "Evaluating configuration 337/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1032\n",
      "\n",
      "Evaluating configuration 338/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 339/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8607\n",
      "\n",
      "Evaluating configuration 340/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 341/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 342/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6863\n",
      "\n",
      "Evaluating configuration 343/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8707\n",
      "\n",
      "Evaluating configuration 344/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6305\n",
      "\n",
      "Evaluating configuration 345/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.0917\n",
      "\n",
      "Evaluating configuration 346/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7545\n",
      "\n",
      "Evaluating configuration 347/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9010\n",
      "\n",
      "Evaluating configuration 348/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7378\n",
      "\n",
      "Evaluating configuration 349/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8925\n",
      "\n",
      "Evaluating configuration 350/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7420\n",
      "\n",
      "Evaluating configuration 351/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8773\n",
      "\n",
      "Evaluating configuration 352/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7135\n",
      "\n",
      "Evaluating configuration 353/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8810\n",
      "\n",
      "Evaluating configuration 354/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.1032\n",
      "\n",
      "Evaluating configuration 355/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8673\n",
      "\n",
      "Evaluating configuration 356/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0978\n",
      "\n",
      "Evaluating configuration 357/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8782\n",
      "\n",
      "Evaluating configuration 358/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.4338\n",
      "\n",
      "Evaluating configuration 359/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8698\n",
      "\n",
      "Evaluating configuration 360/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.5235\n",
      "\n",
      "Evaluating configuration 361/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9005\n",
      "\n",
      "Evaluating configuration 362/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7353\n",
      "\n",
      "Evaluating configuration 363/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8942\n",
      "\n",
      "Evaluating configuration 364/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7195\n",
      "\n",
      "Evaluating configuration 365/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8875\n",
      "\n",
      "Evaluating configuration 366/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7215\n",
      "\n",
      "Evaluating configuration 367/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8803\n",
      "\n",
      "Evaluating configuration 368/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.6917\n",
      "\n",
      "Evaluating configuration 369/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1035\n",
      "\n",
      "Evaluating configuration 370/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.0983\n",
      "\n",
      "Evaluating configuration 371/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8790\n",
      "\n",
      "Evaluating configuration 372/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.1035\n",
      "\n",
      "Evaluating configuration 373/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.1018\n",
      "\n",
      "Evaluating configuration 374/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.5933\n",
      "\n",
      "Evaluating configuration 375/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8700\n",
      "\n",
      "Evaluating configuration 376/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.4067\n",
      "\n",
      "Evaluating configuration 377/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8950\n",
      "\n",
      "Evaluating configuration 378/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7547\n",
      "\n",
      "Evaluating configuration 379/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.9010\n",
      "\n",
      "Evaluating configuration 380/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7378\n",
      "\n",
      "Evaluating configuration 381/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8882\n",
      "\n",
      "Evaluating configuration 382/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 2, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7358\n",
      "\n",
      "Evaluating configuration 383/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "Validation accuracy: 0.8810\n",
      "\n",
      "Evaluating configuration 384/384: {'FC_size': 256, 'activation': 'sigmoid', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 5, 'max_pool_size': 3, 'optimizer': 'sgd'}\n",
      "Validation accuracy: 0.7025\n",
      "\n",
      "\n",
      "Top Configurations:\n",
      "Rank 1:\n",
      "Validation Accuracy: 0.9352\n",
      "Hyperparameters: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "\n",
      "Rank 2:\n",
      "Validation Accuracy: 0.9325\n",
      "Hyperparameters: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "\n",
      "Rank 3:\n",
      "Validation Accuracy: 0.9315\n",
      "Hyperparameters: {'FC_size': 256, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.0, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'random_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "\n",
      "Rank 4:\n",
      "Validation Accuracy: 0.9307\n",
      "Hyperparameters: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.25, 'epochs': 10, 'filters': 28, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 3, 'optimizer': 'adam'}\n",
      "\n",
      "Rank 5:\n",
      "Validation Accuracy: 0.9307\n",
      "Hyperparameters: {'FC_size': 128, 'activation': 'relu', 'batch_size': 128, 'dropout_rate': 0.5, 'epochs': 10, 'filters': 56, 'kernel_initializer': 'he_normal', 'kernel_size': 3, 'max_pool_size': 2, 'optimizer': 'adam'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ConfigSpace import ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import CategoricalHyperparameter, Constant\n",
    "from ConfigSpace.util import generate_grid\n",
    "\n",
    "\n",
    "def train_model(config):\n",
    "    # Extract hyperparameters from the configuration\n",
    "    filters = config['filters']\n",
    "    kernel_size = config['kernel_size']\n",
    "    activation = config['activation']\n",
    "    optimizer = config['optimizer']\n",
    "    batch_size = config['batch_size']\n",
    "    epochs = config['epochs']\n",
    "    kernel_initializer = config['kernel_initializer']\n",
    "    dropout_rate = config['dropout_rate']\n",
    "    max_pool_size = config['max_pool_size']\n",
    "    FC_size = config['FC_size']\n",
    "    \n",
    "#cs.add_hyperparameters([filters, kernel_size, activation, optimizer, batch_size, epochs, kernel_initializer, dropout_rate, max_pool_size, FC_size])\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Conv2D(filters, kernel_size=(kernel_size, kernel_size), activation=activation, input_shape=input_shape, kernel_initializer=kernel_initializer),\n",
    "        Conv2D(filters * 2, kernel_size=(kernel_size, kernel_size), activation=activation, kernel_initializer=kernel_initializer),\n",
    "        MaxPooling2D(pool_size=(max_pool_size, max_pool_size)),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(FC_size, activation=activation, kernel_initializer=kernel_initializer),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Train the model (we will use early stopping if desired)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=0,  # Set to 1 for detailed logs\n",
    "        validation_data=(X_valid, y_valid)\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "\n",
    "    return val_accuracy\n",
    "\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the input data to [0, 1] range\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Split the full training set into training and validation sets\n",
    "val_ratio = 0.1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=val_ratio, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Reshape input data\n",
    "img_rows, img_cols = 28, 28\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_valid = to_categorical(y_valid, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# Define the hyperparameter space\n",
    "cs = ConfigurationSpace()\n",
    "\n",
    "# Hyperparameters\n",
    "filters = CategoricalHyperparameter('filters', [28, 56])\n",
    "kernel_size = CategoricalHyperparameter('kernel_size', [3, 5])\n",
    "kernel_initializer = CategoricalHyperparameter('kernel_initializer', ['random_normal', 'he_normal'])\n",
    "activation = CategoricalHyperparameter('activation', ['relu', 'sigmoid'])\n",
    "optimizer = CategoricalHyperparameter('optimizer', ['adam', 'sgd'])\n",
    "batch_size = Constant('batch_size', 128)\n",
    "epochs = Constant('epochs', 10)\n",
    "dropout_rate = CategoricalHyperparameter('dropout_rate', [0.0, 0.25, 0.5])\n",
    "max_pool_size = CategoricalHyperparameter('max_pool_size', [2,3])\n",
    "FC_size = CategoricalHyperparameter('FC_size', [128, 256])\n",
    "\n",
    "# Add hyperparameters to the configuration space\n",
    "cs.add_hyperparameters([filters, kernel_size, activation, optimizer, batch_size, epochs, kernel_initializer, dropout_rate, max_pool_size, FC_size])\n",
    "\n",
    "# Generate the grid of configurations\n",
    "grid = generate_grid(cs)\n",
    "print(f\"Total configurations to evaluate: {len(grid)}\")\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, config in enumerate(grid):\n",
    "    config_dict = config.get_dictionary()\n",
    "    print(f\"Evaluating configuration {idx + 1}/{len(grid)}: {config_dict}\")\n",
    "    val_accuracy = train_model(config_dict)\n",
    "    print(f\"Validation accuracy: {val_accuracy:.4f}\\n\")\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'config': config_dict,\n",
    "        'val_accuracy': val_accuracy\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Sort the results by validation accuracy in descending order\n",
    "results = sorted(results, key=lambda x: x['val_accuracy'], reverse=True)\n",
    "\n",
    "# Print the top configurations\n",
    "print(\"\\nTop Configurations:\")\n",
    "for rank, result in enumerate(results[:5], start=1):\n",
    "    print(f\"Rank {rank}:\")\n",
    "    print(f\"Validation Accuracy: {result['val_accuracy']:.4f}\")\n",
    "    print(f\"Hyperparameters: {result['config']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (3.9.2)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: scikit-learn in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (1.5.2)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: scipy in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: six in /vol/home/s4422090/miniconda3/envs/IDL/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading statsmodels-0.14.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels, seaborn\n",
      "Successfully installed patsy-0.5.6 seaborn-0.13.2 statsmodels-0.14.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas matplotlib seaborn scikit-learn statsmodels scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis - top 10, ANOVA, mean accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FC_size</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>max_pool_size</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.935167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>random_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>random_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.930667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.930667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>random_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.930667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.930333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>random_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.930333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.929167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>random_normal</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.928833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FC_size activation  batch_size  dropout_rate  epochs  filters  \\\n",
       "0      256       relu         128          0.25      10       56   \n",
       "1      256       relu         128          0.50      10       56   \n",
       "2      256       relu         128          0.00      10       56   \n",
       "3      128       relu         128          0.25      10       28   \n",
       "4      128       relu         128          0.50      10       56   \n",
       "5      256       relu         128          0.50      10       56   \n",
       "6      256       relu         128          0.25      10       28   \n",
       "7      256       relu         128          0.25      10       56   \n",
       "8      256       relu         128          0.50      10       28   \n",
       "9      256       relu         128          0.25      10       28   \n",
       "\n",
       "  kernel_initializer  kernel_size  max_pool_size optimizer  val_accuracy  \n",
       "0          he_normal            3              3      adam      0.935167  \n",
       "1      random_normal            3              2      adam      0.932500  \n",
       "2      random_normal            3              2      adam      0.931500  \n",
       "3          he_normal            3              3      adam      0.930667  \n",
       "4          he_normal            3              2      adam      0.930667  \n",
       "5      random_normal            3              3      adam      0.930667  \n",
       "6          he_normal            3              2      adam      0.930333  \n",
       "7      random_normal            3              3      adam      0.930333  \n",
       "8          he_normal            3              3      adam      0.929167  \n",
       "9      random_normal            3              2      adam      0.928833  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>filters</th>\n",
       "      <td>0.210399</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.371615</td>\n",
       "      <td>0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_size</th>\n",
       "      <td>0.395598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.099875</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_initializer</th>\n",
       "      <td>2.598250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.334982</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation</th>\n",
       "      <td>7.933994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.559925</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>1.646648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.039981</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_rate</th>\n",
       "      <td>0.008565</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.8965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_pool_size</th>\n",
       "      <td>0.380930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.725373</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC_size</th>\n",
       "      <td>0.136938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.496119</td>\n",
       "      <td>0.0623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>14.649066</td>\n",
       "      <td>374.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sum_sq     df           F  PR(>F)\n",
       "filters              0.210399    1.0    5.371615  0.0210\n",
       "kernel_size          0.395598    1.0   10.099875  0.0016\n",
       "kernel_initializer   2.598250    1.0   66.334982  0.0000\n",
       "activation           7.933994    1.0  202.559925  0.0000\n",
       "optimizer            1.646648    1.0   42.039981  0.0000\n",
       "dropout_rate         0.008565    2.0    0.109330  0.8965\n",
       "max_pool_size        0.380930    1.0    9.725373  0.0020\n",
       "FC_size              0.136938    1.0    3.496119  0.0623\n",
       "Residual            14.649066  374.0         NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Accuracy for Each Hyperparameter Value:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameter</th>\n",
       "      <th>Value</th>\n",
       "      <th>Mean Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activation</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.8899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activation</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dropout rate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dropout rate</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dropout rate</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fc size</td>\n",
       "      <td>128</td>\n",
       "      <td>0.7273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fc size</td>\n",
       "      <td>256</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Filters</td>\n",
       "      <td>28</td>\n",
       "      <td>0.7696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Filters</td>\n",
       "      <td>56</td>\n",
       "      <td>0.7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kernel initializer</td>\n",
       "      <td>he_normal</td>\n",
       "      <td>0.8284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kernel initializer</td>\n",
       "      <td>random_normal</td>\n",
       "      <td>0.6639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kernel size</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kernel size</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Max pool size</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Max pool size</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Optimizer</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.6807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Hyperparameter          Value  Mean Val Accuracy\n",
       "0           Activation           relu             0.8899\n",
       "1           Activation        sigmoid             0.6024\n",
       "2         Dropout rate            0.0             0.7516\n",
       "3         Dropout rate           0.25             0.7468\n",
       "4         Dropout rate            0.5             0.7401\n",
       "5              Fc size            128             0.7273\n",
       "6              Fc size            256             0.7650\n",
       "7              Filters             28             0.7696\n",
       "8              Filters             56             0.7227\n",
       "9   Kernel initializer      he_normal             0.8284\n",
       "10  Kernel initializer  random_normal             0.6639\n",
       "11         Kernel size              3             0.7141\n",
       "12         Kernel size              5             0.7783\n",
       "13       Max pool size              2             0.7147\n",
       "14       Max pool size              3             0.7777\n",
       "15           Optimizer           adam             0.8116\n",
       "16           Optimizer            sgd             0.6807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Ensure plots are displayed inline in Jupyter notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Step 2: Convert Results to a DataFrame\n",
    "# Assuming 'results' variable is already defined from your previous code\n",
    "# Convert results to a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Expand the 'config' dictionary into separate columns\n",
    "config_df = pd.json_normalize(df_results['config'])\n",
    "\n",
    "# Combine the validation accuracy with the configurations\n",
    "df = pd.concat([config_df, df_results['val_accuracy']], axis=1)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"First few rows of the DataFrame:\")\n",
    "display(df.head(10))\n",
    "\n",
    "# Step 6: ANOVA Analysis\n",
    "\n",
    "# Exclude constants and numerical hyperparameters\n",
    "anova_hps = ['filters', 'kernel_size', 'kernel_initializer', 'activation', 'optimizer', 'dropout_rate', 'max_pool_size', 'FC_size']\n",
    "\n",
    "# Prepare the data for ANOVA\n",
    "df_anova = df.copy()\n",
    "\n",
    "# Convert hyperparameters to categorical data types\n",
    "for col in anova_hps:\n",
    "    df_anova[col] = df_anova[col].astype('category')\n",
    "\n",
    "# Construct the formula for ANOVA\n",
    "formula = 'val_accuracy ~ ' + ' + '.join(anova_hps)\n",
    "\n",
    "# Perform ANOVA\n",
    "model = ols(formula, data=df_anova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Round the 'PR(>F)' column to four decimal places\n",
    "anova_table['PR(>F)'] = anova_table['PR(>F)'].round(4)\n",
    "\n",
    "# Alternatively, to format 'PR(>F)' as strings with four decimal places:\n",
    "# anova_table['PR(>F)'] = anova_table['PR(>F)'].apply(lambda x: \"{0:.4f}\".format(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(\"ANOVA Table:\")\n",
    "display(anova_table)\n",
    "\n",
    "# List of hyperparameters to include in the table (excluding constants if any)\n",
    "hyperparameters = [\n",
    "    'filters', \n",
    "    'kernel_size', \n",
    "    'kernel_initializer', \n",
    "    'activation', \n",
    "    'optimizer', \n",
    "    'dropout_rate', \n",
    "    'max_pool_size', \n",
    "    'FC_size'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store mean accuracy data for each hyperparameter\n",
    "mean_accuracy_list = []\n",
    "\n",
    "# Loop through each hyperparameter to calculate mean validation accuracy per value\n",
    "for hp in hyperparameters:\n",
    "    # Group by the hyperparameter and calculate the mean validation accuracy\n",
    "    hp_mean = df.groupby(hp)['val_accuracy'].mean().reset_index()\n",
    "    \n",
    "    # Rename the 'val_accuracy' column to 'Mean Val Accuracy'\n",
    "    hp_mean = hp_mean.rename(columns={'val_accuracy': 'Mean Val Accuracy', hp: 'Value'})\n",
    "    \n",
    "    # Add a column to indicate which hyperparameter the row corresponds to\n",
    "    hp_mean.insert(0, 'Hyperparameter', hp.replace('_', ' ').capitalize())\n",
    "    \n",
    "    # Append the result to the list\n",
    "    mean_accuracy_list.append(hp_mean)\n",
    "\n",
    "# Concatenate all the individual hyperparameter DataFrames into one\n",
    "mean_accuracy_df = pd.concat(mean_accuracy_list, ignore_index=True)\n",
    "\n",
    "# Round the mean validation accuracy to four decimal places for clarity\n",
    "mean_accuracy_df['Mean Val Accuracy'] = mean_accuracy_df['Mean Val Accuracy'].round(4)\n",
    "\n",
    "# Optional: Sort the table by Hyperparameter and then by Value for better readability\n",
    "mean_accuracy_df = mean_accuracy_df.sort_values(['Hyperparameter', 'Value']).reset_index(drop=True)\n",
    "\n",
    "# Display the final table\n",
    "print(\"Average Validation Accuracy for Each Hyperparameter Value:\")\n",
    "display(mean_accuracy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taking the best perfroming configuration and making it deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 1 block(s)...\n",
      "Validation accuracy with 1 block(s): 0.9293\n",
      "Training model with 2 block(s)...\n",
      "Validation accuracy with 2 block(s): 0.9245\n",
      "Training model with 3 block(s)...\n",
      "Validation accuracy with 3 block(s): 0.9248\n",
      "Training model with 4 block(s)...\n",
      "Validation accuracy with 4 block(s): 0.9242\n",
      "Training model with 5 block(s)...\n",
      "Skipping MaxPooling2D at block 4 due to small spatial dimensions (1x1)\n",
      "Validation accuracy with 5 block(s): 0.9217\n",
      "Validation accuracy with 1 block(s): 0.9293\n",
      "Validation accuracy with 2 block(s): 0.9245\n",
      "Validation accuracy with 3 block(s): 0.9248\n",
      "Validation accuracy with 4 block(s): 0.9242\n",
      "Validation accuracy with 5 block(s): 0.9217\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess data\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "val_ratio = 0.1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=val_ratio, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_valid = to_categorical(y_valid, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "kernel_initializer = 'he_normal'\n",
    "\n",
    "# Function to build the model with a given number of blocks\n",
    "def build_model(num_blocks):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(28, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_initializer=kernel_initializer))\n",
    "    model.add(Conv2D(28, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    current_dim = img_rows // 2  # 28 / 2 = 14\n",
    "\n",
    "    for i in range(1, num_blocks):\n",
    "        filters = 28 * (2 ** i)\n",
    "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer))\n",
    "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer))\n",
    "        # Check if pooling can be applied\n",
    "        if current_dim >= 2:\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            current_dim = current_dim // 2  # Update current spatial dimension\n",
    "        else:\n",
    "            print(f\"Skipping MaxPooling2D at block {i} due to small spatial dimensions ({current_dim}x{current_dim})\")\n",
    "\n",
    "        model.add(Dropout(0.25))       \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer=kernel_initializer))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Loop through the number of blocks and evaluate the model\n",
    "validation_accuracies = []\n",
    "\n",
    "for num_blocks in range(1, 4):\n",
    "    print(f\"Training model with {num_blocks} block(s)...\")\n",
    "    model = build_model(num_blocks)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=0,\n",
    "        validation_data=(X_valid, y_valid)\n",
    "    )\n",
    "    score = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "    validation_accuracies.append(score[1])\n",
    "    print(f\"Validation accuracy with {num_blocks} block(s): {score[1]:.4f}\")\n",
    "\n",
    "# Print the validation accuracies for each number of blocks\n",
    "for num_blocks, val_acc in enumerate(validation_accuracies, start=1):\n",
    "    print(f\"Validation accuracy with {num_blocks} block(s): {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfering the architecture to CIFAR\n",
    "\n",
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Num GPUs Available: 1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "X_train shape: (45000, 32, 32, 3)\n",
      "45000 train samples\n",
      "5000 validation samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4422090/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8023793697357178\n",
      "Test accuracy: 0.7321000099182129\n",
      "Test loss: 0.7898674607276917\n",
      "Test accuracy: 0.7337999939918518\n",
      "Test loss: 1.0871012210845947\n",
      "Test accuracy: 0.7192999720573425\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Verify TensorFlow installation and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for each GPU to prevent TensorFlow from allocating all GPU memory at once\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")\n",
    "\n",
    "# 1. Load the CIFAR-10 dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 2. Normalize the input data to [0, 1] range\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# 3. Split the full training set into training and validation sets\n",
    "val_ratio = 0.1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=val_ratio, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 4. Define class names for reference (optional)\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# 5. Print dataset shapes for verification\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# 6. Set input shape based on CIFAR-10 images\n",
    "img_rows, img_cols, img_channels = 32, 32, 3\n",
    "input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "# 7. Flatten label arrays\n",
    "y_train = y_train.flatten()\n",
    "y_valid = y_valid.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# 8. Convert class vectors to binary class matrices (one-hot encoding)\n",
    "num_classes = 10  # There are 10 classes in CIFAR-10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_valid = to_categorical(y_valid, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "kernel_initializer = 'he_normal'\n",
    "\n",
    "# 9. Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_initializer=kernel_initializer),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# 10. Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',      # Suitable loss function for multi-class classification\n",
    "    optimizer='adam',                     # Adam optimizer\n",
    "    metrics=['accuracy']                  # Evaluate performance using accuracy\n",
    ")\n",
    "\n",
    "# 11. Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "    validation_data=(X_valid, y_valid)    # Use validation set for monitoring\n",
    ")\n",
    "\n",
    "# 12. Evaluate the model on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# config 2\n",
    "\n",
    "kernel_initializer = 'random_normal'\n",
    "\n",
    "# 9. Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_initializer=kernel_initializer),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# 10. Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',      # Suitable loss function for multi-class classification\n",
    "    optimizer='adam',                     # Adam optimizer\n",
    "    metrics=['accuracy']                  # Evaluate performance using accuracy\n",
    ")\n",
    "\n",
    "# 11. Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "    validation_data=(X_valid, y_valid)    # Use validation set for monitoring\n",
    ")\n",
    "\n",
    "# 12. Evaluate the model on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "# config 3\n",
    "\n",
    "kernel_initializer = 'random_normal'\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_initializer=kernel_initializer),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.0),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',     \n",
    "    optimizer='adam',                     \n",
    "    metrics=['accuracy']                  \n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    verbose=0,\n",
    "    validation_data=(X_valid, y_valid)    \n",
    ")\n",
    "\n",
    "# 12. Evaluate the model on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10, plot 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Num GPUs Available: 1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "X_train shape: (45000, 32, 32, 3)\n",
      "45000 train samples\n",
      "5000 validation samples\n",
      "10000 test samples\n",
      "Epoch 1/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1815 - loss: 2.3669 - val_accuracy: 0.3942 - val_loss: 1.6377\n",
      "Epoch 2/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3846 - loss: 1.6522 - val_accuracy: 0.4666 - val_loss: 1.4478\n",
      "Epoch 3/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4447 - loss: 1.5061 - val_accuracy: 0.5218 - val_loss: 1.3257\n",
      "Epoch 4/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4875 - loss: 1.4081 - val_accuracy: 0.5238 - val_loss: 1.3001\n",
      "Epoch 5/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5203 - loss: 1.3213 - val_accuracy: 0.5816 - val_loss: 1.1672\n",
      "Epoch 6/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5557 - loss: 1.2503 - val_accuracy: 0.5746 - val_loss: 1.1489\n",
      "Epoch 7/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5737 - loss: 1.1861 - val_accuracy: 0.6518 - val_loss: 0.9879\n",
      "Epoch 8/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5958 - loss: 1.1345 - val_accuracy: 0.6654 - val_loss: 0.9377\n",
      "Epoch 9/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6108 - loss: 1.0928 - val_accuracy: 0.6564 - val_loss: 0.9495\n",
      "Epoch 10/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6294 - loss: 1.0459 - val_accuracy: 0.6914 - val_loss: 0.8802\n",
      "Epoch 11/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6404 - loss: 1.0134 - val_accuracy: 0.7150 - val_loss: 0.8297\n",
      "Epoch 12/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6471 - loss: 1.0003 - val_accuracy: 0.7116 - val_loss: 0.8177\n",
      "Epoch 13/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6531 - loss: 0.9805 - val_accuracy: 0.7176 - val_loss: 0.8113\n",
      "Epoch 14/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6649 - loss: 0.9561 - val_accuracy: 0.7282 - val_loss: 0.7897\n",
      "Epoch 15/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.9320 - val_accuracy: 0.7296 - val_loss: 0.7765\n",
      "Epoch 16/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.9240 - val_accuracy: 0.7244 - val_loss: 0.7844\n",
      "Epoch 17/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6791 - loss: 0.9075 - val_accuracy: 0.7348 - val_loss: 0.7605\n",
      "Epoch 18/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6823 - loss: 0.9002 - val_accuracy: 0.7468 - val_loss: 0.7350\n",
      "Epoch 19/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6933 - loss: 0.8723 - val_accuracy: 0.7396 - val_loss: 0.7441\n",
      "Epoch 20/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.8644 - val_accuracy: 0.7420 - val_loss: 0.7505\n",
      "Epoch 21/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6957 - loss: 0.8657 - val_accuracy: 0.7414 - val_loss: 0.7366\n",
      "Epoch 22/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 0.8659 - val_accuracy: 0.7450 - val_loss: 0.7231\n",
      "Epoch 23/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6993 - loss: 0.8572 - val_accuracy: 0.7604 - val_loss: 0.6915\n",
      "Epoch 24/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7084 - loss: 0.8278 - val_accuracy: 0.7622 - val_loss: 0.7027\n",
      "Epoch 25/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7099 - loss: 0.8251 - val_accuracy: 0.7484 - val_loss: 0.7154\n",
      "Epoch 26/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7081 - loss: 0.8300 - val_accuracy: 0.7574 - val_loss: 0.6890\n",
      "Epoch 27/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7091 - loss: 0.8173 - val_accuracy: 0.7576 - val_loss: 0.7012\n",
      "Epoch 28/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7132 - loss: 0.8137 - val_accuracy: 0.7704 - val_loss: 0.6768\n",
      "Epoch 29/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7164 - loss: 0.8064 - val_accuracy: 0.7500 - val_loss: 0.7070\n",
      "Epoch 30/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7179 - loss: 0.8016 - val_accuracy: 0.7536 - val_loss: 0.7090\n",
      "Epoch 31/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.8006 - val_accuracy: 0.7632 - val_loss: 0.6861\n",
      "Epoch 32/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.7924 - val_accuracy: 0.7706 - val_loss: 0.6656\n",
      "Epoch 33/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.7896 - val_accuracy: 0.7688 - val_loss: 0.6650\n",
      "Epoch 34/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7270 - loss: 0.7810 - val_accuracy: 0.7760 - val_loss: 0.6521\n",
      "Epoch 35/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7293 - loss: 0.7775 - val_accuracy: 0.7702 - val_loss: 0.6580\n",
      "Epoch 36/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.7786 - val_accuracy: 0.7656 - val_loss: 0.6739\n",
      "Epoch 37/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7277 - loss: 0.7760 - val_accuracy: 0.7726 - val_loss: 0.6618\n",
      "Epoch 38/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7313 - loss: 0.7733 - val_accuracy: 0.7740 - val_loss: 0.6525\n",
      "Epoch 39/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.7597 - val_accuracy: 0.7666 - val_loss: 0.6783\n",
      "Epoch 40/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7390 - loss: 0.7472 - val_accuracy: 0.7608 - val_loss: 0.6870\n",
      "Epoch 41/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.7658 - val_accuracy: 0.7686 - val_loss: 0.6660\n",
      "Epoch 42/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.7603 - val_accuracy: 0.7840 - val_loss: 0.6352\n",
      "Epoch 43/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.7475 - val_accuracy: 0.7810 - val_loss: 0.6308\n",
      "Epoch 44/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7336 - loss: 0.7557 - val_accuracy: 0.7916 - val_loss: 0.6255\n",
      "Epoch 45/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7398 - loss: 0.7437 - val_accuracy: 0.7710 - val_loss: 0.6648\n",
      "Epoch 46/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.7440 - val_accuracy: 0.7816 - val_loss: 0.6312\n",
      "Epoch 47/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7368 - loss: 0.7496 - val_accuracy: 0.7774 - val_loss: 0.6340\n",
      "Epoch 48/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7436 - loss: 0.7296 - val_accuracy: 0.7844 - val_loss: 0.6247\n",
      "Epoch 49/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.7292 - val_accuracy: 0.7818 - val_loss: 0.6236\n",
      "Epoch 50/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7428 - loss: 0.7313 - val_accuracy: 0.7844 - val_loss: 0.6288\n",
      "Epoch 51/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.7306 - val_accuracy: 0.7864 - val_loss: 0.6267\n",
      "Epoch 52/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7449 - loss: 0.7296 - val_accuracy: 0.7892 - val_loss: 0.6249\n",
      "Epoch 53/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7456 - loss: 0.7271 - val_accuracy: 0.7862 - val_loss: 0.6133\n",
      "Epoch 54/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.7219 - val_accuracy: 0.7912 - val_loss: 0.6137\n",
      "Epoch 55/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.7156 - val_accuracy: 0.7914 - val_loss: 0.6112\n",
      "Epoch 56/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7453 - loss: 0.7189 - val_accuracy: 0.7942 - val_loss: 0.6019\n",
      "Epoch 57/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7478 - loss: 0.7147 - val_accuracy: 0.7842 - val_loss: 0.6202\n",
      "Epoch 58/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7473 - loss: 0.7126 - val_accuracy: 0.7946 - val_loss: 0.6044\n",
      "Epoch 59/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7519 - loss: 0.7086 - val_accuracy: 0.7932 - val_loss: 0.6104\n",
      "Epoch 60/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.7133 - val_accuracy: 0.7986 - val_loss: 0.6014\n",
      "Epoch 61/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7450 - loss: 0.7187 - val_accuracy: 0.7912 - val_loss: 0.6054\n",
      "Epoch 62/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7540 - loss: 0.7088 - val_accuracy: 0.7830 - val_loss: 0.6251\n",
      "Epoch 63/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.7057 - val_accuracy: 0.7964 - val_loss: 0.6145\n",
      "Epoch 64/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7555 - loss: 0.7023 - val_accuracy: 0.7974 - val_loss: 0.5916\n",
      "Epoch 65/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7546 - loss: 0.7039 - val_accuracy: 0.7768 - val_loss: 0.6313\n",
      "Epoch 66/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.6945 - val_accuracy: 0.7984 - val_loss: 0.5873\n",
      "Epoch 67/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.7004 - val_accuracy: 0.8006 - val_loss: 0.5945\n",
      "Epoch 68/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7572 - loss: 0.6948 - val_accuracy: 0.7952 - val_loss: 0.6032\n",
      "Epoch 69/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.7009 - val_accuracy: 0.7972 - val_loss: 0.6034\n",
      "Epoch 70/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7591 - loss: 0.6860 - val_accuracy: 0.7994 - val_loss: 0.5881\n",
      "Epoch 71/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7564 - loss: 0.6907 - val_accuracy: 0.7946 - val_loss: 0.6024\n",
      "Epoch 72/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.6973 - val_accuracy: 0.7992 - val_loss: 0.5973\n",
      "Epoch 73/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.6886 - val_accuracy: 0.8026 - val_loss: 0.5927\n",
      "Epoch 74/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7621 - loss: 0.6775 - val_accuracy: 0.8050 - val_loss: 0.5797\n",
      "Epoch 75/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7613 - loss: 0.6793 - val_accuracy: 0.8034 - val_loss: 0.5763\n",
      "Epoch 76/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7612 - loss: 0.6829 - val_accuracy: 0.8036 - val_loss: 0.5788\n",
      "Epoch 77/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7611 - loss: 0.6821 - val_accuracy: 0.7942 - val_loss: 0.5887\n",
      "Epoch 78/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.6868 - val_accuracy: 0.7912 - val_loss: 0.6006\n",
      "Epoch 79/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7598 - loss: 0.6790 - val_accuracy: 0.7982 - val_loss: 0.5928\n",
      "Epoch 80/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.6831 - val_accuracy: 0.7976 - val_loss: 0.5775\n",
      "Epoch 81/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7663 - loss: 0.6719 - val_accuracy: 0.7960 - val_loss: 0.5914\n",
      "Epoch 82/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7649 - loss: 0.6733 - val_accuracy: 0.8026 - val_loss: 0.5762\n",
      "Epoch 83/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.6700 - val_accuracy: 0.7962 - val_loss: 0.5875\n",
      "Epoch 84/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.6736 - val_accuracy: 0.8094 - val_loss: 0.5760\n",
      "Epoch 85/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.6690 - val_accuracy: 0.7938 - val_loss: 0.5964\n",
      "Epoch 86/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.6804 - val_accuracy: 0.8070 - val_loss: 0.5712\n",
      "Epoch 87/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.6542 - val_accuracy: 0.8034 - val_loss: 0.5776\n",
      "Epoch 88/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.6722 - val_accuracy: 0.8068 - val_loss: 0.5619\n",
      "Epoch 89/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7663 - loss: 0.6721 - val_accuracy: 0.7986 - val_loss: 0.5745\n",
      "Epoch 90/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.6632 - val_accuracy: 0.8024 - val_loss: 0.5747\n",
      "Epoch 91/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7634 - loss: 0.6731 - val_accuracy: 0.8052 - val_loss: 0.5812\n",
      "Epoch 92/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7631 - loss: 0.6758 - val_accuracy: 0.7988 - val_loss: 0.5810\n",
      "Epoch 93/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7632 - loss: 0.6779 - val_accuracy: 0.8046 - val_loss: 0.5806\n",
      "Epoch 94/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.6701 - val_accuracy: 0.7952 - val_loss: 0.5955\n",
      "Epoch 95/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7679 - loss: 0.6621 - val_accuracy: 0.8044 - val_loss: 0.5809\n",
      "Epoch 96/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 0.6636 - val_accuracy: 0.8034 - val_loss: 0.5748\n",
      "Epoch 97/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7711 - loss: 0.6517 - val_accuracy: 0.7940 - val_loss: 0.5940\n",
      "Epoch 98/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 0.6611 - val_accuracy: 0.7972 - val_loss: 0.5912\n",
      "Epoch 99/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.6563 - val_accuracy: 0.8058 - val_loss: 0.5762\n",
      "Epoch 100/100\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7696 - loss: 0.6620 - val_accuracy: 0.8002 - val_loss: 0.5783\n",
      "Test loss: 0.5913046598434448\n",
      "Test accuracy: 0.7964000105857849\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt  # Import for plotting\n",
    "\n",
    "# Verify TensorFlow installation and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for each GPU to prevent TensorFlow from allocating all GPU memory at once\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")\n",
    "\n",
    "# 1. Load the CIFAR-10 dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 2. Normalize the input data to [0, 1] range\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# 3. Split the full training set into training and validation sets\n",
    "val_ratio = 0.1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=val_ratio, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 4. Define class names for reference (optional)\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# 5. Print dataset shapes for verification\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# 6. Set input shape based on CIFAR-10 images\n",
    "img_rows, img_cols, img_channels = 32, 32, 3\n",
    "input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "# 7. Flatten label arrays\n",
    "y_train = y_train.flatten()\n",
    "y_valid = y_valid.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# 8. Convert class vectors to binary class matrices (one-hot encoding)\n",
    "num_classes = 10  # There are 10 classes in CIFAR-10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_valid = to_categorical(y_valid, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "kernel_initializer = 'he_normal'\n",
    "\n",
    "# 9. Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_initializer=kernel_initializer),\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu', kernel_initializer=kernel_initializer),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# 10. Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',      # Suitable loss function for multi-class classification\n",
    "    optimizer='adam',                     # Adam optimizer\n",
    "    metrics=['accuracy']                  # Evaluate performance using accuracy\n",
    ")\n",
    "\n",
    "# 11. Train the model and capture the history\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=(X_valid, y_valid)    # Use validation set for monitoring\n",
    ")\n",
    "\n",
    "# 12. Evaluate the model on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# 13. Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy over 100 Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Num GPUs Available: 1\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "X_train shape: (45000, 32, 32, 3)\n",
      "45000 train samples\n",
      "5000 validation samples\n",
      "10000 test samples\n",
      "Training model with 1 block(s)...\n",
      "Validation accuracy with 1 block(s): 0.7114\n",
      "Training model with 2 block(s)...\n",
      "Validation accuracy with 2 block(s): 0.7740\n",
      "Training model with 3 block(s)...\n",
      "Validation accuracy with 3 block(s): 0.7866\n",
      "Training model with 4 block(s)...\n",
      "Validation accuracy with 4 block(s): 0.7764\n",
      "Validation accuracy with 1 block(s): 0.7114\n",
      "Validation accuracy with 2 block(s): 0.7740\n",
      "Validation accuracy with 3 block(s): 0.7866\n",
      "Validation accuracy with 4 block(s): 0.7764\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Verify TensorFlow installation and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for each GPU to prevent TensorFlow from allocating all GPU memory at once\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")\n",
    "\n",
    "# 1. Load the CIFAR-10 dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 2. Normalize the input data to [0, 1] range\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# 3. Split the full training set into training and validation sets\n",
    "val_ratio = 0.1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=val_ratio, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 4. Define class names for reference (optional)\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# 5. Print dataset shapes for verification\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# 6. Set input shape based on CIFAR-10 images\n",
    "img_rows, img_cols, img_channels = 32, 32, 3\n",
    "input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "# 7. Flatten label arrays\n",
    "y_train = y_train.flatten()\n",
    "y_valid = y_valid.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# 8. Convert class vectors to binary class matrices (one-hot encoding)\n",
    "num_classes = 10  # There are 10 classes in CIFAR-10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_valid = to_categorical(y_valid, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "kernel_initializer = 'he_normal'\n",
    "\n",
    "# 9. Define the CNN model\n",
    "def build_model(num_blocks):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape, kernel_initializer=kernel_initializer))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    for i in range(1, num_blocks):\n",
    "        filters = 32 * (2 ** i)\n",
    "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer))\n",
    "        model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer=kernel_initializer))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer=kernel_initializer))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',    \n",
    "        optimizer='adam',                     \n",
    "        metrics=['accuracy']                 \n",
    "    )\n",
    "    return model\n",
    "\n",
    "validation_accuracies = []\n",
    "\n",
    "for num_blocks in range(1, 5):\n",
    "    print(f\"Training model with {num_blocks} block(s)...\")\n",
    "    model = build_model(num_blocks)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=0,\n",
    "        validation_data=(X_valid, y_valid)\n",
    "    )\n",
    "    score = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "    validation_accuracies.append(score[1])\n",
    "    print(f\"Validation accuracy with {num_blocks} block(s): {score[1]:.4f}\")\n",
    "\n",
    "# Print the validation accuracies for each number of blocks\n",
    "for num_blocks, val_acc in enumerate(validation_accuracies, start=1):\n",
    "    print(f\"Validation accuracy with {num_blocks} block(s): {val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 substask 1 b - Regression CNN for Tell the Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data_file.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimages = np.load(data_dir + \"/images.npy\")\\n\\nprint(images.shape)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Download the input data \n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "url = \"https://surfdrive.surf.nl/files/index.php/s/GsH5DxUdBgDR64B/download\"\n",
    "file_name = \"data_file.zip\"\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open(file_name, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"Downloaded {file_name}\")\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Define the directory containing the images\n",
    "image_path = \"data/images.npy\"\n",
    "\n",
    "\n",
    "images = np.load(data_dir + \"/images.npy\")\n",
    "\n",
    "print(images.shape)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model - MSE loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 23.8270 - mae: 3.8496 - val_loss: 11.9852 - val_mae: 2.9837\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 12.8688 - mae: 3.0758 - val_loss: 11.8538 - val_mae: 2.9682\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 12.6744 - mae: 3.0530 - val_loss: 12.0023 - val_mae: 2.9759\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 12.6607 - mae: 3.0487 - val_loss: 11.8961 - val_mae: 2.9640\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 12.5072 - mae: 3.0295 - val_loss: 11.3340 - val_mae: 2.8746\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 12.1019 - mae: 2.9540 - val_loss: 11.3021 - val_mae: 2.8199\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 11.5593 - mae: 2.8492 - val_loss: 10.3293 - val_mae: 2.6865\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 10.7481 - mae: 2.7134 - val_loss: 10.1919 - val_mae: 2.6087\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 10.3244 - mae: 2.6271 - val_loss: 9.7773 - val_mae: 2.5382\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 10.3540 - mae: 2.6254 - val_loss: 9.4217 - val_mae: 2.4952\n",
      "Test loss (MAE): 9.697487831115723\n",
      "Test Mean Absolute Error (MAE): 2.5075623989105225\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_split_data(images_path, labels_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "    images = np.load(images_path)\n",
    "    labels = np.load(labels_path) \n",
    "\n",
    "    # Normalize the images to [0,1]\n",
    "    images = images.astype('float32') / 255.0 \n",
    "    \n",
    "\n",
    "    num_samples, height, width = images.shape\n",
    "\n",
    "    # Shuffle + separate into training, validation, test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, \n",
    "        test_size= (1 - train_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size= val_ratio / (test_ratio + val_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )   \n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "def label_transformation(labels):\n",
    "\n",
    "    hours = labels[:, 0].astype(float)\n",
    "    minutes = labels[:, 1].astype(float)\n",
    "\n",
    "    # Convert time to continuous value: hour + minutes/60\n",
    "    continuous_labels = hours + minutes / 60.0\n",
    "    return continuous_labels\n",
    "\n",
    "def time_loss_function(y_true, y_pred):\n",
    "    if np.abs(y_true - y_pred) > 6:\n",
    "        if y_true > 6:\n",
    "            y_true = y_true - 12\n",
    "        else:\n",
    "            y_true = y_true + 12\n",
    "\n",
    "    return np.abs(y_true - y_pred)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_path = \"data/images.npy\"\n",
    "    labels_path = 'labels.npy'\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_and_split_data(images_path=images_path, labels_path=labels_path)\n",
    "\n",
    "    # Transform the labels to continuous values\n",
    "    y_test_cont = label_transformation(y_test)\n",
    "    y_train_cont = label_transformation(y_train)\n",
    "    y_val_cont = label_transformation(y_val)\n",
    "\n",
    "\n",
    "    width, height = X_train.shape[1], X_train.shape[2]\n",
    "    input_shape = (width, height, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.25),  \n",
    "        Dense(1)  \n",
    "    ])\n",
    "        \n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',  \n",
    "        optimizer='adam',                    \n",
    "        metrics=['mae']  # Mean Absolute Error \n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_cont,\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val_cont)   \n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test_cont, verbose=0)\n",
    "    print('Test loss (MAE):', score[0])\n",
    "    print('Test Mean Absolute Error (MAE):', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right loss function - baseline\n",
    "\n",
    "Notes:\n",
    "it doesnt get better with more epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - absolute_time_loss_function: 2.8061 - loss: 12.1232 - val_absolute_time_loss_function: 3.0381 - val_loss: 12.1927\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.9839 - loss: 11.9207 - val_absolute_time_loss_function: 3.0380 - val_loss: 12.1917\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.9926 - loss: 12.0409 - val_absolute_time_loss_function: 2.8954 - val_loss: 12.1254\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.8443 - loss: 11.8461 - val_absolute_time_loss_function: 2.9916 - val_loss: 12.3004\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.8761 - loss: 11.9624 - val_absolute_time_loss_function: 3.0385 - val_loss: 12.2065\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.9565 - loss: 12.0377 - val_absolute_time_loss_function: 2.6222 - val_loss: 12.2669\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.7518 - loss: 11.9830 - val_absolute_time_loss_function: 3.0164 - val_loss: 12.1966\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.8330 - loss: 11.7435 - val_absolute_time_loss_function: 2.8901 - val_loss: 11.6768\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 2.6630 - loss: 10.7133 - val_absolute_time_loss_function: 2.0993 - val_loss: 8.0845\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - absolute_time_loss_function: 1.9207 - loss: 8.5668 - val_absolute_time_loss_function: 2.1918 - val_loss: 7.9973\n",
      "Test loss: 8.389448165893555\n",
      "Test mean minute error 131.65592193603516\n",
      "Test mean minute error 2.194265365600586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "def load_and_split_data(images_path, labels_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "    images = np.load(images_path)\n",
    "    labels = np.load(labels_path) \n",
    "\n",
    "    # Normalize the images to [0,1]\n",
    "    images = images.astype('float32') / 255.0 \n",
    "    \n",
    "\n",
    "    num_samples, height, width = images.shape\n",
    "\n",
    "    # Shuffle + separate into training, validation, test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, \n",
    "        test_size= (1 - train_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size= val_ratio / (test_ratio + val_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )   \n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "def label_transformation(labels):\n",
    "\n",
    "    hours = labels[:, 0].astype(float)\n",
    "    minutes = labels[:, 1].astype(float)\n",
    "\n",
    "    # Convert time to continuous value: hour + minutes/60\n",
    "    continuous_labels = hours + minutes / 60.0\n",
    "    return continuous_labels\n",
    "\n",
    "def square_time_loss_function(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    circular_diff = tf.minimum(diff, 12 - diff)\n",
    "    return tf.square(circular_diff)\n",
    "\n",
    "def absolute_time_loss_function(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    circular_diff = tf.minimum(diff, 12 - diff)\n",
    "    return circular_diff\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_path = \"data/images.npy\"\n",
    "    labels_path = 'labels.npy'\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_and_split_data(images_path=images_path, labels_path=labels_path)\n",
    "\n",
    "\n",
    "    # Transform the labels to continuous values\n",
    "    y_test_cont = label_transformation(y_test)\n",
    "    y_train_cont = label_transformation(y_train)\n",
    "    y_val_cont = label_transformation(y_val)\n",
    "\n",
    "\n",
    "\n",
    "    width, height = X_train.shape[1], X_train.shape[2]\n",
    "    input_shape = (width, height, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.25),  \n",
    "        Dense(1)  # Output layer for regression, single continuous output\n",
    "    ]) \n",
    "\n",
    "    #   Dense(1, activation='sigmoid'),  # Output layer for regression, single continuous output\n",
    "    #   Lambda(lambda x: x * 12)  #  make it be between 0 and 12\n",
    "\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss= square_time_loss_function,  \n",
    "        optimizer='adam',                    \n",
    "        metrics=[absolute_time_loss_function]  # Mean Absolute Error as an additional metric\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_cont,\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val_cont)   \n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test_cont, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test mean minute error', score[1]*60)\n",
    "    print('Test mean minute error', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct loss function with modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - absolute_time_loss_function: 2.5574 - loss: 11.9809 - val_absolute_time_loss_function: 3.0383 - val_loss: 12.2055\n",
      "Epoch 2/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 2.9758 - loss: 11.9417 - val_absolute_time_loss_function: 3.0386 - val_loss: 12.2043\n",
      "Epoch 3/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 3.0014 - loss: 12.0641 - val_absolute_time_loss_function: 3.0387 - val_loss: 12.1979\n",
      "Epoch 4/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 2.9930 - loss: 11.9809 - val_absolute_time_loss_function: 3.0379 - val_loss: 12.1301\n",
      "Epoch 5/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 2.7825 - loss: 10.9146 - val_absolute_time_loss_function: 2.1227 - val_loss: 8.5043\n",
      "Epoch 6/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 2.2852 - loss: 8.2397 - val_absolute_time_loss_function: 1.8415 - val_loss: 6.8586\n",
      "Epoch 7/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.8815 - loss: 7.1192 - val_absolute_time_loss_function: 1.3590 - val_loss: 6.1942\n",
      "Epoch 8/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.7762 - loss: 6.2995 - val_absolute_time_loss_function: 2.0755 - val_loss: 5.3825\n",
      "Epoch 9/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.7125 - loss: 5.4204 - val_absolute_time_loss_function: 1.6446 - val_loss: 4.3411\n",
      "Epoch 10/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.6604 - loss: 4.7919 - val_absolute_time_loss_function: 1.8254 - val_loss: 3.7730\n",
      "Epoch 11/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.6414 - loss: 4.0484 - val_absolute_time_loss_function: 1.6721 - val_loss: 3.8155\n",
      "Epoch 12/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.6378 - loss: 3.8023 - val_absolute_time_loss_function: 1.6759 - val_loss: 3.0383\n",
      "Epoch 13/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.6099 - loss: 3.3335 - val_absolute_time_loss_function: 1.6099 - val_loss: 2.8803\n",
      "Epoch 14/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5858 - loss: 3.2007 - val_absolute_time_loss_function: 1.8066 - val_loss: 2.9814\n",
      "Epoch 15/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5590 - loss: 3.0700 - val_absolute_time_loss_function: 1.7240 - val_loss: 2.7764\n",
      "Epoch 16/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5335 - loss: 2.9842 - val_absolute_time_loss_function: 1.4782 - val_loss: 2.5328\n",
      "Epoch 17/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5346 - loss: 2.8026 - val_absolute_time_loss_function: 1.6350 - val_loss: 2.3741\n",
      "Epoch 18/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5396 - loss: 2.7723 - val_absolute_time_loss_function: 1.6930 - val_loss: 2.3316\n",
      "Epoch 19/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5499 - loss: 2.5829 - val_absolute_time_loss_function: 1.5957 - val_loss: 2.2956\n",
      "Epoch 20/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5652 - loss: 2.6579 - val_absolute_time_loss_function: 1.3583 - val_loss: 2.2379\n",
      "Epoch 21/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5537 - loss: 2.5078 - val_absolute_time_loss_function: 1.7790 - val_loss: 2.2854\n",
      "Epoch 22/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5316 - loss: 2.4552 - val_absolute_time_loss_function: 1.6847 - val_loss: 2.1562\n",
      "Epoch 23/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5697 - loss: 2.2849 - val_absolute_time_loss_function: 1.5878 - val_loss: 2.0553\n",
      "Epoch 24/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5284 - loss: 2.2985 - val_absolute_time_loss_function: 1.6782 - val_loss: 2.0523\n",
      "Epoch 25/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4949 - loss: 2.1590 - val_absolute_time_loss_function: 1.6356 - val_loss: 1.9608\n",
      "Epoch 26/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4992 - loss: 2.1068 - val_absolute_time_loss_function: 1.5911 - val_loss: 1.9007\n",
      "Epoch 27/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5334 - loss: 2.0898 - val_absolute_time_loss_function: 1.6641 - val_loss: 1.9698\n",
      "Epoch 28/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5106 - loss: 2.1099 - val_absolute_time_loss_function: 1.5953 - val_loss: 1.9454\n",
      "Epoch 29/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5328 - loss: 1.9354 - val_absolute_time_loss_function: 1.6312 - val_loss: 1.8905\n",
      "Epoch 30/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5211 - loss: 1.9786 - val_absolute_time_loss_function: 1.6810 - val_loss: 1.8390\n",
      "Epoch 31/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5171 - loss: 1.8829 - val_absolute_time_loss_function: 1.5648 - val_loss: 1.7717\n",
      "Epoch 32/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4954 - loss: 1.9070 - val_absolute_time_loss_function: 1.6088 - val_loss: 1.6804\n",
      "Epoch 33/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5357 - loss: 1.8706 - val_absolute_time_loss_function: 1.8052 - val_loss: 2.3448\n",
      "Epoch 34/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5136 - loss: 1.9080 - val_absolute_time_loss_function: 1.4793 - val_loss: 1.6949\n",
      "Epoch 35/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4823 - loss: 1.7084 - val_absolute_time_loss_function: 1.5507 - val_loss: 1.6698\n",
      "Epoch 36/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4993 - loss: 1.6892 - val_absolute_time_loss_function: 1.4336 - val_loss: 1.7417\n",
      "Epoch 37/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4936 - loss: 1.7663 - val_absolute_time_loss_function: 1.5976 - val_loss: 1.6491\n",
      "Epoch 38/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4799 - loss: 1.6841 - val_absolute_time_loss_function: 1.5841 - val_loss: 1.6474\n",
      "Epoch 39/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4840 - loss: 1.6716 - val_absolute_time_loss_function: 1.6009 - val_loss: 1.6814\n",
      "Epoch 40/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4964 - loss: 1.7304 - val_absolute_time_loss_function: 1.5579 - val_loss: 1.6724\n",
      "Epoch 41/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5091 - loss: 1.6232 - val_absolute_time_loss_function: 1.5599 - val_loss: 1.7400\n",
      "Epoch 42/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4934 - loss: 1.6316 - val_absolute_time_loss_function: 1.6227 - val_loss: 1.6415\n",
      "Epoch 43/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4869 - loss: 1.5844 - val_absolute_time_loss_function: 1.6546 - val_loss: 1.6265\n",
      "Epoch 44/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4636 - loss: 1.5765 - val_absolute_time_loss_function: 1.4887 - val_loss: 1.6066\n",
      "Epoch 45/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4708 - loss: 1.5233 - val_absolute_time_loss_function: 1.6642 - val_loss: 1.6311\n",
      "Epoch 46/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4910 - loss: 1.4857 - val_absolute_time_loss_function: 1.4967 - val_loss: 1.5596\n",
      "Epoch 47/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4973 - loss: 1.5133 - val_absolute_time_loss_function: 1.7469 - val_loss: 1.7854\n",
      "Epoch 48/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4862 - loss: 1.5199 - val_absolute_time_loss_function: 1.3936 - val_loss: 1.5612\n",
      "Epoch 49/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.4739 - loss: 1.4566 - val_absolute_time_loss_function: 1.6244 - val_loss: 1.5568\n",
      "Epoch 50/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - absolute_time_loss_function: 1.5121 - loss: 1.4267 - val_absolute_time_loss_function: 1.5347 - val_loss: 1.6078\n",
      "Test loss: 1.465691089630127\n",
      "Test mean minute error: 92.6986813545227\n",
      "Test mean hour error: 1.5449780225753784\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "def load_and_split_data(images_path, labels_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "    images = np.load(images_path)\n",
    "    labels = np.load(labels_path) \n",
    "\n",
    "    # Normalize the images to [0,1]\n",
    "    images = images.astype('float32') / 255.0 \n",
    "    \n",
    "\n",
    "    num_samples, height, width = images.shape\n",
    "\n",
    "    # Shuffle + separate into training, validation, test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, \n",
    "        test_size= (1 - train_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size= val_ratio / (test_ratio + val_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )   \n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "def label_transformation(labels):\n",
    "\n",
    "    hours = labels[:, 0].astype(float)\n",
    "    minutes = labels[:, 1].astype(float)\n",
    "\n",
    "    # Convert time to continuous value: hour + minutes/60\n",
    "    continuous_labels = hours + minutes / 60.0\n",
    "    return continuous_labels\n",
    "\n",
    "def square_time_loss_function(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    circular_diff = tf.minimum(diff, 12 - diff)\n",
    "    return tf.square(circular_diff)\n",
    "\n",
    "def absolute_time_loss_function(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    circular_diff = tf.minimum(diff, 12 - diff)\n",
    "    return circular_diff\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_path = \"data/images.npy\"\n",
    "    labels_path = 'labels.npy'\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_and_split_data(images_path=images_path, labels_path=labels_path)\n",
    "\n",
    "\n",
    "    # Transform the labels to continuous values\n",
    "    y_test_cont = label_transformation(y_test)\n",
    "    y_train_cont = label_transformation(y_train)\n",
    "    y_val_cont = label_transformation(y_val)\n",
    "\n",
    "\n",
    "    width, height = X_train.shape[1], X_train.shape[2]\n",
    "    input_shape = (width, height, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.25),  \n",
    "        Dense(1)  \n",
    "    ]) \n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss= square_time_loss_function,  \n",
    "        optimizer='adam',                    \n",
    "        metrics=[absolute_time_loss_function]  # Mean Absolute Error as an additional metric\n",
    "    )\n",
    "\n",
    "    \n",
    "   # Train the model and capture the history\n",
    "    history = model.fit(\n",
    "        X_train, y_train_cont,\n",
    "        batch_size=128,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val_cont)\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test_cont, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test mean minute error:', score[1] * 60)  \n",
    "    print('Test mean hour error:', score[1])  \n",
    "\n",
    "\n",
    "    # Plot training & validation absolute_time_loss_function values\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['absolute_time_loss_function'], label='Train')\n",
    "    plt.plot(history.history['val_absolute_time_loss_function'], label='Validation')\n",
    "    plt.title('Model absolute_time_loss_function')\n",
    "    plt.ylabel('absolute_time_loss_function')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 epochs plot val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - absolute_time_loss_function: 2.6820 - loss: 12.1434 - val_absolute_time_loss_function: 3.0375 - val_loss: 12.1875\n",
      "Epoch 2/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 3.0005 - loss: 11.9829 - val_absolute_time_loss_function: 3.0374 - val_loss: 12.1865\n",
      "Epoch 3/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.9984 - loss: 11.9658 - val_absolute_time_loss_function: 3.0376 - val_loss: 12.1882\n",
      "Epoch 4/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.9956 - loss: 11.9323 - val_absolute_time_loss_function: 3.0379 - val_loss: 12.1906\n",
      "Epoch 5/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 3.0006 - loss: 12.0146 - val_absolute_time_loss_function: 3.0380 - val_loss: 12.1923\n",
      "Epoch 6/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - absolute_time_loss_function: 2.9955 - loss: 11.9679 - val_absolute_time_loss_function: 3.0384 - val_loss: 12.1948\n",
      "Epoch 7/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.9755 - loss: 11.8434 - val_absolute_time_loss_function: 2.9692 - val_loss: 11.7861\n",
      "Epoch 8/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.8467 - loss: 11.4756 - val_absolute_time_loss_function: 3.0287 - val_loss: 12.0295\n",
      "Epoch 9/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.7173 - loss: 10.6196 - val_absolute_time_loss_function: 2.6022 - val_loss: 7.9442\n",
      "Epoch 10/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.5134 - loss: 8.1700 - val_absolute_time_loss_function: 2.6169 - val_loss: 6.8427\n",
      "Epoch 11/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.4954 - loss: 6.9878 - val_absolute_time_loss_function: 2.5513 - val_loss: 6.1526\n",
      "Epoch 12/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.4359 - loss: 6.4081 - val_absolute_time_loss_function: 2.5597 - val_loss: 5.9081\n",
      "Epoch 13/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3986 - loss: 5.6170 - val_absolute_time_loss_function: 2.6155 - val_loss: 5.5682\n",
      "Epoch 14/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3544 - loss: 5.3834 - val_absolute_time_loss_function: 2.5652 - val_loss: 4.8910\n",
      "Epoch 15/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3797 - loss: 4.8831 - val_absolute_time_loss_function: 2.5126 - val_loss: 4.6593\n",
      "Epoch 16/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3533 - loss: 4.6994 - val_absolute_time_loss_function: 2.4486 - val_loss: 4.2192\n",
      "Epoch 17/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3411 - loss: 4.3580 - val_absolute_time_loss_function: 2.4373 - val_loss: 3.6613\n",
      "Epoch 18/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3336 - loss: 4.2563 - val_absolute_time_loss_function: 2.4812 - val_loss: 3.6671\n",
      "Epoch 19/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2985 - loss: 4.1638 - val_absolute_time_loss_function: 2.5679 - val_loss: 3.4285\n",
      "Epoch 20/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3766 - loss: 3.7546 - val_absolute_time_loss_function: 2.4151 - val_loss: 3.2699\n",
      "Epoch 21/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3261 - loss: 3.5192 - val_absolute_time_loss_function: 2.4371 - val_loss: 2.9433\n",
      "Epoch 22/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3124 - loss: 3.3648 - val_absolute_time_loss_function: 2.4991 - val_loss: 3.0778\n",
      "Epoch 23/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3505 - loss: 3.3255 - val_absolute_time_loss_function: 2.5993 - val_loss: 3.3150\n",
      "Epoch 24/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3222 - loss: 3.0701 - val_absolute_time_loss_function: 2.3446 - val_loss: 3.5710\n",
      "Epoch 25/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2386 - loss: 3.4053 - val_absolute_time_loss_function: 2.4015 - val_loss: 2.2866\n",
      "Epoch 26/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2798 - loss: 2.8590 - val_absolute_time_loss_function: 2.4779 - val_loss: 2.4674\n",
      "Epoch 27/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3110 - loss: 2.9467 - val_absolute_time_loss_function: 2.2795 - val_loss: 2.2665\n",
      "Epoch 28/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2972 - loss: 2.8340 - val_absolute_time_loss_function: 2.1653 - val_loss: 2.7739\n",
      "Epoch 29/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1463 - loss: 2.9701 - val_absolute_time_loss_function: 2.4020 - val_loss: 2.3984\n",
      "Epoch 30/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3553 - loss: 2.7554 - val_absolute_time_loss_function: 2.4497 - val_loss: 2.0946\n",
      "Epoch 31/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2229 - loss: 2.5484 - val_absolute_time_loss_function: 2.5550 - val_loss: 2.5631\n",
      "Epoch 32/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - absolute_time_loss_function: 2.3385 - loss: 2.7914 - val_absolute_time_loss_function: 2.3357 - val_loss: 2.2878\n",
      "Epoch 33/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2249 - loss: 2.4831 - val_absolute_time_loss_function: 2.3368 - val_loss: 2.1195\n",
      "Epoch 34/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2523 - loss: 2.4939 - val_absolute_time_loss_function: 2.2884 - val_loss: 1.7164\n",
      "Epoch 35/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2907 - loss: 2.3310 - val_absolute_time_loss_function: 2.3437 - val_loss: 1.7756\n",
      "Epoch 36/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2974 - loss: 2.4145 - val_absolute_time_loss_function: 2.5972 - val_loss: 2.2912\n",
      "Epoch 37/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3830 - loss: 2.4348 - val_absolute_time_loss_function: 2.4329 - val_loss: 2.0673\n",
      "Epoch 38/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2632 - loss: 2.2967 - val_absolute_time_loss_function: 2.3745 - val_loss: 1.7573\n",
      "Epoch 39/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2688 - loss: 2.2170 - val_absolute_time_loss_function: 2.1817 - val_loss: 2.0882\n",
      "Epoch 40/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2210 - loss: 2.3603 - val_absolute_time_loss_function: 2.4073 - val_loss: 1.9621\n",
      "Epoch 41/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1504 - loss: 2.3224 - val_absolute_time_loss_function: 2.3327 - val_loss: 1.6463\n",
      "Epoch 42/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1955 - loss: 2.2728 - val_absolute_time_loss_function: 2.5684 - val_loss: 2.5475\n",
      "Epoch 43/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2931 - loss: 2.1319 - val_absolute_time_loss_function: 2.3468 - val_loss: 1.6420\n",
      "Epoch 44/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2562 - loss: 2.0992 - val_absolute_time_loss_function: 2.4621 - val_loss: 1.9253\n",
      "Epoch 45/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2331 - loss: 2.1533 - val_absolute_time_loss_function: 2.2946 - val_loss: 1.6437\n",
      "Epoch 46/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2223 - loss: 2.1146 - val_absolute_time_loss_function: 2.2355 - val_loss: 1.5413\n",
      "Epoch 47/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2292 - loss: 1.9705 - val_absolute_time_loss_function: 2.2477 - val_loss: 1.5959\n",
      "Epoch 48/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2082 - loss: 2.1738 - val_absolute_time_loss_function: 2.5483 - val_loss: 2.1773\n",
      "Epoch 49/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3220 - loss: 2.2742 - val_absolute_time_loss_function: 2.4350 - val_loss: 1.5196\n",
      "Epoch 50/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2277 - loss: 2.0268 - val_absolute_time_loss_function: 2.2184 - val_loss: 1.6962\n",
      "Epoch 51/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2310 - loss: 1.9153 - val_absolute_time_loss_function: 2.4736 - val_loss: 1.8991\n",
      "Epoch 52/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2255 - loss: 2.1761 - val_absolute_time_loss_function: 2.2147 - val_loss: 1.4382\n",
      "Epoch 53/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2726 - loss: 1.8424 - val_absolute_time_loss_function: 2.3526 - val_loss: 1.5655\n",
      "Epoch 54/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2605 - loss: 1.9164 - val_absolute_time_loss_function: 2.3848 - val_loss: 1.7273\n",
      "Epoch 55/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2273 - loss: 1.9563 - val_absolute_time_loss_function: 2.3902 - val_loss: 1.3722\n",
      "Epoch 56/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3064 - loss: 1.9326 - val_absolute_time_loss_function: 2.1134 - val_loss: 1.3170\n",
      "Epoch 57/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1990 - loss: 1.8727 - val_absolute_time_loss_function: 2.4193 - val_loss: 1.6386\n",
      "Epoch 58/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2085 - loss: 2.0632 - val_absolute_time_loss_function: 1.9743 - val_loss: 1.3406\n",
      "Epoch 59/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1638 - loss: 1.9061 - val_absolute_time_loss_function: 2.3010 - val_loss: 1.4095\n",
      "Epoch 60/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2187 - loss: 1.9024 - val_absolute_time_loss_function: 2.3122 - val_loss: 1.5433\n",
      "Epoch 61/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2328 - loss: 1.7811 - val_absolute_time_loss_function: 2.2819 - val_loss: 1.6319\n",
      "Epoch 62/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1879 - loss: 1.9222 - val_absolute_time_loss_function: 2.2442 - val_loss: 1.1437\n",
      "Epoch 63/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2594 - loss: 1.7276 - val_absolute_time_loss_function: 2.1957 - val_loss: 1.2597\n",
      "Epoch 64/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1869 - loss: 1.7458 - val_absolute_time_loss_function: 2.2601 - val_loss: 1.9108\n",
      "Epoch 65/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1463 - loss: 2.0751 - val_absolute_time_loss_function: 2.3320 - val_loss: 1.4739\n",
      "Epoch 66/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3049 - loss: 1.9026 - val_absolute_time_loss_function: 2.1693 - val_loss: 1.4333\n",
      "Epoch 67/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2735 - loss: 1.7554 - val_absolute_time_loss_function: 2.1458 - val_loss: 1.3195\n",
      "Epoch 68/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2021 - loss: 1.8459 - val_absolute_time_loss_function: 2.2637 - val_loss: 1.1648\n",
      "Epoch 69/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2307 - loss: 1.6492 - val_absolute_time_loss_function: 2.2835 - val_loss: 1.2281\n",
      "Epoch 70/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2037 - loss: 1.5922 - val_absolute_time_loss_function: 2.3109 - val_loss: 1.2391\n",
      "Epoch 71/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1891 - loss: 1.6390 - val_absolute_time_loss_function: 2.0933 - val_loss: 1.1633\n",
      "Epoch 72/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1827 - loss: 1.6217 - val_absolute_time_loss_function: 2.1650 - val_loss: 1.3007\n",
      "Epoch 73/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2621 - loss: 1.8846 - val_absolute_time_loss_function: 2.2233 - val_loss: 1.2764\n",
      "Epoch 74/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2313 - loss: 1.7224 - val_absolute_time_loss_function: 2.1364 - val_loss: 1.1834\n",
      "Epoch 75/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1679 - loss: 1.8066 - val_absolute_time_loss_function: 2.3111 - val_loss: 1.1877\n",
      "Epoch 76/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2427 - loss: 1.6521 - val_absolute_time_loss_function: 2.0958 - val_loss: 1.1065\n",
      "Epoch 77/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2238 - loss: 1.5373 - val_absolute_time_loss_function: 2.2678 - val_loss: 1.1567\n",
      "Epoch 78/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2237 - loss: 1.6230 - val_absolute_time_loss_function: 2.4863 - val_loss: 1.8256\n",
      "Epoch 79/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2366 - loss: 1.8526 - val_absolute_time_loss_function: 1.6152 - val_loss: 1.7706\n",
      "Epoch 80/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 1.8785 - loss: 2.1824 - val_absolute_time_loss_function: 2.0583 - val_loss: 1.1922\n",
      "Epoch 81/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1845 - loss: 1.8064 - val_absolute_time_loss_function: 2.3434 - val_loss: 1.1316\n",
      "Epoch 82/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1842 - loss: 1.5397 - val_absolute_time_loss_function: 2.0314 - val_loss: 1.1779\n",
      "Epoch 83/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2487 - loss: 1.6740 - val_absolute_time_loss_function: 2.3292 - val_loss: 1.1753\n",
      "Epoch 84/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1732 - loss: 1.6828 - val_absolute_time_loss_function: 2.4848 - val_loss: 1.9942\n",
      "Epoch 85/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3286 - loss: 1.8006 - val_absolute_time_loss_function: 2.1674 - val_loss: 1.1223\n",
      "Epoch 86/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2474 - loss: 1.5183 - val_absolute_time_loss_function: 2.1942 - val_loss: 1.1860\n",
      "Epoch 87/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3266 - loss: 1.7396 - val_absolute_time_loss_function: 2.3282 - val_loss: 0.9662\n",
      "Epoch 88/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2928 - loss: 1.5246 - val_absolute_time_loss_function: 2.0732 - val_loss: 1.3113\n",
      "Epoch 89/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2233 - loss: 1.5591 - val_absolute_time_loss_function: 2.2853 - val_loss: 0.9497\n",
      "Epoch 90/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2337 - loss: 1.5284 - val_absolute_time_loss_function: 2.1435 - val_loss: 1.0882\n",
      "Epoch 91/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2178 - loss: 1.6152 - val_absolute_time_loss_function: 2.2248 - val_loss: 0.9749\n",
      "Epoch 92/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3060 - loss: 1.6007 - val_absolute_time_loss_function: 2.1181 - val_loss: 1.0793\n",
      "Epoch 93/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2646 - loss: 1.6406 - val_absolute_time_loss_function: 2.3905 - val_loss: 1.1131\n",
      "Epoch 94/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2907 - loss: 1.6634 - val_absolute_time_loss_function: 2.2176 - val_loss: 0.9881\n",
      "Epoch 95/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2560 - loss: 1.4365 - val_absolute_time_loss_function: 2.2909 - val_loss: 0.8730\n",
      "Epoch 96/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2688 - loss: 1.3779 - val_absolute_time_loss_function: 2.2123 - val_loss: 0.9999\n",
      "Epoch 97/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.1992 - loss: 1.3861 - val_absolute_time_loss_function: 2.3060 - val_loss: 1.0132\n",
      "Epoch 98/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2961 - loss: 1.4746 - val_absolute_time_loss_function: 2.3374 - val_loss: 1.0377\n",
      "Epoch 99/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.2772 - loss: 1.4864 - val_absolute_time_loss_function: 2.4558 - val_loss: 1.3377\n",
      "Epoch 100/100\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - absolute_time_loss_function: 2.3753 - loss: 1.5903 - val_absolute_time_loss_function: 2.2605 - val_loss: 1.0141\n",
      "Test loss: 1.0026557445526123\n",
      "Test mean minute error: 133.8345193862915\n",
      "Test mean hour error: 2.2305753231048584\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "def load_and_split_data(images_path, labels_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "    images = np.load(images_path)\n",
    "    labels = np.load(labels_path) \n",
    "\n",
    "    # Normalize the images to [0,1]\n",
    "    images = images.astype('float32') / 255.0 \n",
    "    \n",
    "\n",
    "    num_samples, height, width = images.shape\n",
    "\n",
    "    # Shuffle + separate into training, validation, test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, \n",
    "        test_size= (1 - train_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size= val_ratio / (test_ratio + val_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )   \n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "def label_transformation(labels):\n",
    "\n",
    "    hours = labels[:, 0].astype(float)\n",
    "    minutes = labels[:, 1].astype(float)\n",
    "\n",
    "    # Convert time to continuous value: hour + minutes/60\n",
    "    continuous_labels = hours + minutes / 60.0\n",
    "    return continuous_labels\n",
    "\n",
    "def square_time_loss_function(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    circular_diff = tf.minimum(diff, 12 - diff)\n",
    "    return tf.square(circular_diff)\n",
    "\n",
    "def absolute_time_loss_function(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    circular_diff = tf.minimum(diff, 12 - diff)\n",
    "    return circular_diff\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_path = \"data/images.npy\"\n",
    "    labels_path = 'labels.npy'\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_and_split_data(images_path=images_path, labels_path=labels_path)\n",
    "\n",
    "\n",
    "    # Transform the labels to continuous values\n",
    "    y_test_cont = label_transformation(y_test)\n",
    "    y_train_cont = label_transformation(y_train)\n",
    "    y_val_cont = label_transformation(y_val)\n",
    "\n",
    "\n",
    "    width, height = X_train.shape[1], X_train.shape[2]\n",
    "    input_shape = (width, height, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25), \n",
    "\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),  \n",
    "        Dense(1)  \n",
    "    ]) \n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss= square_time_loss_function,  \n",
    "        optimizer='adam',                    \n",
    "        metrics=[absolute_time_loss_function]  # Mean Absolute Error as an additional metric\n",
    "    )\n",
    "\n",
    "     \n",
    "   # Train the model and capture the history\n",
    "    history = model.fit(\n",
    "        X_train, y_train_cont,\n",
    "        batch_size=128,\n",
    "        epochs=100,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val_cont)\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test_cont, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test mean minute error:', score[1] * 60)  \n",
    "    print('Test mean hour error:', score[1])  \n",
    "\n",
    "\n",
    "    # Plot training & validation absolute_time_loss_function values\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['absolute_time_loss_function'], label='Train')\n",
    "    plt.plot(history.history['val_absolute_time_loss_function'], label='Validation')\n",
    "    plt.title('Model absolute_time_loss_function')\n",
    "    plt.ylabel('absolute_time_loss_function')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## double head attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4422090/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730746927.125608 2854425 service.cc:148] XLA service 0x7feb6801cfc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730746927.125635 2854425 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2024-11-04 20:02:07.140979: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1730746927.206244 2854425 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-04 20:02:07.275104: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/225\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:41\u001b[0m 6s/step - absolute_time_loss_function: 3.4721 - loss: 1.7344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730746931.996795 2854425 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m224/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - absolute_time_loss_function: 3.7275 - loss: 0.9302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 20:02:25.934772: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 69ms/step - absolute_time_loss_function: 3.7256 - loss: 0.9301 - val_absolute_time_loss_function: 3.1929 - val_loss: 0.6398\n",
      "Epoch 2/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 4.1560 - loss: 0.9610 - val_absolute_time_loss_function: 3.0249 - val_loss: 0.6977\n",
      "Epoch 3/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 3.6622 - loss: 0.8855 - val_absolute_time_loss_function: 3.2642 - val_loss: 0.6361\n",
      "Epoch 4/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 4.0698 - loss: 0.9030 - val_absolute_time_loss_function: 3.1119 - val_loss: 0.6475\n",
      "Epoch 5/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 3.9789 - loss: 1.0179 - val_absolute_time_loss_function: 3.0405 - val_loss: 0.6753\n",
      "Epoch 6/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 3.5161 - loss: 0.8398 - val_absolute_time_loss_function: 3.0495 - val_loss: 0.6996\n",
      "Epoch 7/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 3.6326 - loss: 0.8121 - val_absolute_time_loss_function: 3.0542 - val_loss: 0.6622\n",
      "Epoch 8/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 4.1635 - loss: 1.0299 - val_absolute_time_loss_function: 3.2900 - val_loss: 0.6370\n",
      "Epoch 9/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 3.8675 - loss: 0.8490 - val_absolute_time_loss_function: 3.0520 - val_loss: 0.6652\n",
      "Epoch 10/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - absolute_time_loss_function: 3.6582 - loss: 0.8993 - val_absolute_time_loss_function: 3.0559 - val_loss: 0.9332\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test_cont' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 109\u001b[0m\n\u001b[1;32m    100\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    101\u001b[0m     X_train, y_train_heads,\n\u001b[1;32m    102\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val_heads)   \n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test_cont, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest mean hour error\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_cont' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import Lambda\n",
    "\n",
    "\n",
    "def load_and_split_data(images_path, labels_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "    images = np.load(images_path)\n",
    "    labels = np.load(labels_path) \n",
    "\n",
    "    # Normalize the images to [0,1]\n",
    "    images = images.astype('float32') / 255.0 \n",
    "    \n",
    "\n",
    "    num_samples, height, width = images.shape\n",
    "\n",
    "    # Shuffle + separate into training, validation, test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, \n",
    "        test_size= (1 - train_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size= val_ratio / (test_ratio + val_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )   \n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "def label_transformation(labels):\n",
    "\n",
    "    hours = labels[:, 0].astype(float)\n",
    "    minutes = labels[:, 1].astype(float)\n",
    "\n",
    "    return hours, minutes\n",
    "\n",
    "def square_time_loss_function(y_true, y_pred):\n",
    "    diff1 = tf.abs(y_true[0] - y_pred[0])\n",
    "    diff2 = tf.abs(y_true[1] - y_pred[1])\n",
    "\n",
    "    circular_diff1 = tf.minimum(diff1, 12 - diff1)\n",
    "    circular_diff2 = tf.minimum(diff2, 60 - diff2)\n",
    "\n",
    "    norm1 = tf.square(circular_diff1)/144\n",
    "    norm2 = tf.square(circular_diff2)/3600\n",
    "\n",
    "    return 10*(norm1 + norm2)\n",
    "\n",
    "def absolute_time_loss_function(y_true, y_pred):\n",
    "    diff1 = tf.abs(y_true[0] - y_pred[0])\n",
    "    diff2 = tf.abs(y_true[1] - y_pred[1])\n",
    "\n",
    "    circular_diff1 = tf.minimum(diff1, 12 - diff1)\n",
    "    circular_diff2 = tf.minimum(diff2, 60 - diff2)\n",
    "\n",
    "    return [circular_diff1,circular_diff2]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_path = \"data/images.npy\"\n",
    "    labels_path = 'labels.npy'\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_and_split_data(images_path=images_path, labels_path=labels_path)\n",
    "\n",
    "\n",
    "    # Transform the labels to continuous values\n",
    "    y_test_heads = label_transformation(y_test)\n",
    "    y_train_heads = label_transformation(y_train)\n",
    "    y_val_heads = label_transformation(y_val)\n",
    "\n",
    "\n",
    "\n",
    "    width, height = X_train.shape[1], X_train.shape[2]\n",
    "    input_shape = (width, height, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(75, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "\n",
    "        Conv2D(150, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),  \n",
    "\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.25),  \n",
    "        Dense(2)  \n",
    "    ]) \n",
    "\n",
    "    model.compile(\n",
    "        loss= square_time_loss_function,  \n",
    "        optimizer='adam',                    \n",
    "        metrics=[absolute_time_loss_function]  # Mean Absolute Error as an additional metric\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train_heads,\n",
    "        batch_size=64,\n",
    "        epochs=10,\n",
    "        verbose=1,\n",
    "        validation_data=(X_val, y_val_heads)   \n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(X_test, y_test_cont, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test mean hour error', score[1])\n",
    "    print('Test mean minute error', score[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full solution gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s4422090/.local/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 119ms/step - hour_output_loss: 0.9988 - hour_output_mae: 1.9817 - loss: 6.6406 - minute_output_accuracy: 0.0172 - minute_output_loss: 5.6405 - val_hour_output_loss: 1.0098 - val_hour_output_mae: 0.6371 - val_loss: 5.1032 - val_minute_output_accuracy: 0.0194 - val_minute_output_loss: 4.0947\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 1.0023 - hour_output_mae: 0.6376 - loss: 5.0966 - minute_output_accuracy: 0.0162 - minute_output_loss: 4.0944 - val_hour_output_loss: 1.0193 - val_hour_output_mae: 0.6373 - val_loss: 5.1152 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0951\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 0.9869 - hour_output_mae: 0.6364 - loss: 5.0832 - minute_output_accuracy: 0.0198 - minute_output_loss: 4.0943 - val_hour_output_loss: 1.0194 - val_hour_output_mae: 0.6373 - val_loss: 5.1157 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0955\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 0.9945 - hour_output_mae: 0.6362 - loss: 5.0888 - minute_output_accuracy: 0.0164 - minute_output_loss: 4.0942 - val_hour_output_loss: 1.0191 - val_hour_output_mae: 0.6374 - val_loss: 5.1158 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0958\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 0.9986 - hour_output_mae: 0.6360 - loss: 5.0928 - minute_output_accuracy: 0.0169 - minute_output_loss: 4.0943 - val_hour_output_loss: 1.0185 - val_hour_output_mae: 0.6374 - val_loss: 5.1157 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0961\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 0.9991 - hour_output_mae: 0.6371 - loss: 5.0931 - minute_output_accuracy: 0.0196 - minute_output_loss: 4.0941 - val_hour_output_loss: 1.0194 - val_hour_output_mae: 0.6374 - val_loss: 5.1166 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0963\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 0.9953 - hour_output_mae: 0.6366 - loss: 5.0892 - minute_output_accuracy: 0.0192 - minute_output_loss: 4.0942 - val_hour_output_loss: 1.0185 - val_hour_output_mae: 0.6375 - val_loss: 5.1162 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0965\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 1.0000 - hour_output_mae: 0.6366 - loss: 5.0944 - minute_output_accuracy: 0.0183 - minute_output_loss: 4.0944 - val_hour_output_loss: 1.0193 - val_hour_output_mae: 0.6375 - val_loss: 5.1170 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0968\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 1.0029 - hour_output_mae: 0.6372 - loss: 5.0970 - minute_output_accuracy: 0.0195 - minute_output_loss: 4.0940 - val_hour_output_loss: 1.0187 - val_hour_output_mae: 0.6376 - val_loss: 5.1167 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0969\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - hour_output_loss: 0.9949 - hour_output_mae: 0.6369 - loss: 5.0892 - minute_output_accuracy: 0.0183 - minute_output_loss: 4.0942 - val_hour_output_loss: 1.0187 - val_hour_output_mae: 0.6376 - val_loss: 5.1169 - val_minute_output_accuracy: 0.0128 - val_minute_output_loss: 4.0970\n",
      "Test loss: 5.10517692565918\n",
      "Test hour MAE: 0.6356047987937927\n",
      "Test minute accuracy: 0.010555555112659931\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, add, BatchNormalization, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Updated import\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_and_split_data(images_path, labels_path, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_state=42):\n",
    "    images = np.load(images_path)\n",
    "    labels = np.load(labels_path) \n",
    "\n",
    "    # Normalize the images to [0,1]\n",
    "    images = images.astype('float32') / 255.0 \n",
    "\n",
    "    num_samples, height, width = images.shape\n",
    "\n",
    "    # Expand dimensions to include channel dimension\n",
    "    images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "    # Shuffle + separate into training, validation, test\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, labels, \n",
    "        test_size= (1 - train_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size= test_ratio / (test_ratio + val_ratio), \n",
    "        random_state=random_state, \n",
    "        shuffle=True\n",
    "    )   \n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "def label_transformation(labels):\n",
    "    # Convert hours and minutes to angles in radians\n",
    "    hours = labels[:, 0] % 12  # Ensure hours are in 0-11\n",
    "    minutes = labels[:, 1]\n",
    "    \n",
    "    hour_angles = (hours + minutes / 60.0) * (2 * np.pi / 12.0)  # Convert time to angle in radians\n",
    "    hour_sin = np.sin(hour_angles)\n",
    "    hour_cos = np.cos(hour_angles)\n",
    "    \n",
    "    # For minutes, we keep them as integers (0-59) for classification\n",
    "    minute_labels = labels[:, 1].astype(int)\n",
    "    \n",
    "    return hour_sin, hour_cos, minute_labels\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3,3), stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or x.shape[-1] != shortcut.shape[-1]:\n",
    "        shortcut = Conv2D(filters, kernel_size=(1,1), strides=stride, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def cosine_loss(y_true, y_pred):\n",
    "    # Compute cosine loss between true and predicted vectors\n",
    "    y_true = tf.math.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = tf.math.l2_normalize(y_pred, axis=-1)\n",
    "    loss = 1 - tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    return loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    images_path = \"data/images.npy\"\n",
    "    labels_path = 'labels.npy'\n",
    "    \n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_and_split_data(images_path=images_path, labels_path=labels_path)\n",
    "    \n",
    "    # Transform the labels\n",
    "    y_train_hour_sin, y_train_hour_cos, y_train_minute = label_transformation(y_train)\n",
    "    y_val_hour_sin, y_val_hour_cos, y_val_minute = label_transformation(y_val)\n",
    "    y_test_hour_sin, y_test_hour_cos, y_test_minute = label_transformation(y_test)\n",
    "    \n",
    "    # Combine hour sin and cos into one array for regression output\n",
    "    y_train_hour = np.stack((y_train_hour_sin, y_train_hour_cos), axis=-1)\n",
    "    y_val_hour = np.stack((y_val_hour_sin, y_val_hour_cos), axis=-1)\n",
    "    y_test_hour = np.stack((y_test_hour_sin, y_test_hour_cos), axis=-1)\n",
    "    \n",
    "    # Data augmentation with only rotations and shifts\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2\n",
    "    )\n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    # Build the model\n",
    "    width, height = X_train.shape[1], X_train.shape[2]\n",
    "    input_shape = (width, height, 1)\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(32, kernel_size=(3,3), strides=1, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = residual_block(x, filters=32)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x = residual_block(x, filters=64)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x = residual_block(x, filters=128)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Hour head (regression)\n",
    "    hour_output = Dense(2, activation='linear', name='hour_output')(x)  # Predicting sin and cos of hour angle\n",
    "    \n",
    "    # Minute head (classification)\n",
    "    minute_output = Dense(60, activation='softmax', name='minute_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[hour_output, minute_output])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'hour_output': cosine_loss, 'minute_output': 'sparse_categorical_crossentropy'},\n",
    "        metrics={'hour_output': 'mae', 'minute_output': 'accuracy'}\n",
    "    )\n",
    "    \n",
    "    batch_size = 128\n",
    "    \n",
    "    train_generator = datagen.flow(\n",
    "        X_train, {'hour_output': y_train_hour, 'minute_output': y_train_minute},\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    steps_per_epoch = len(X_train) // batch_size\n",
    "    \n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=10,\n",
    "        validation_data=(X_val, {'hour_output': y_val_hour, 'minute_output': y_val_minute})\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_metrics = model.evaluate(X_test, {'hour_output': y_test_hour, 'minute_output': y_test_minute}, verbose=0)\n",
    "    print('Test loss:', test_metrics[0])\n",
    "    print('Test minutes MAE:', test_metrics[3]*60+test_metrics[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test minutes MAE: 38.14684348274022\n"
     ]
    }
   ],
   "source": [
    "print('Test minutes MAE:', test_metrics[3]*60+test_metrics[4])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
